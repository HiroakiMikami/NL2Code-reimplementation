{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NL2Prog/hearthstone/treegen/train",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yje9hqtcUQ_f",
        "colab_type": "text"
      },
      "source": [
        "### Initialization\n",
        "* Check whether the runtime is host or local.\n",
        "* Mount Google Drive when using the host runtime."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwqGy_GyUQnw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/gdrive')\n",
        "    runtime = \"host\"\n",
        "except:\n",
        "    runtime = \"local\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_S457sT6QMUr",
        "colab_type": "text"
      },
      "source": [
        "### Parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LYvG4iCQUwh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = 20367 #@param {type: \"number\"}\n",
        "\n",
        "repository_url = \"https://github.com/HiroakiMikami/NL2Prog\" #@param {type: \"string\"}\n",
        "branch_name = \"master\" #@param {type: \"string\"}\n",
        "\n",
        "word_threshold =  3 #@param {type: \"number\"}\n",
        "token_threshold = 0 #@param {type: \"number\"}\n",
        "max_token_len = 32 #@param {type: \"number\"}\n",
        "max_arity = 16 #@param {type: \"number\"}\n",
        "\n",
        "num_heads = 1 #@param {type: \"number\"}\n",
        "num_nl_reader_blocks = 6 #@param {type: \"number\"}\n",
        "num_ast_reader_blocks = 6 #@param {type: \"number\"}\n",
        "num_decoder_blocks = 6 #@param {type: \"number\"}\n",
        "hidden_size = 256 #@param {type: \"number\"}\n",
        "feature_size = 1024  #@param {type: \"number\"}\n",
        "\n",
        "batch_size = 1 #@param {type: \"number\"}\n",
        "dropout = 0.15 #@param {type: \"number\"}\n",
        "num_epochs = 50 #@param {type: \"number\"}\n",
        "num_train = 0 #@param {type: \"number\"}\n",
        "num_save_models = 3 #@param {type: \"number\"}\n",
        "\n",
        "device = 0 #@param {type: \"number\"}\n",
        "\n",
        "output_dir_path = \"/gdrive/My Drive/NL2Prog/hearthstone/treegen\" #@param {type: \"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BembldCdOO1",
        "colab_type": "text"
      },
      "source": [
        "### Setup\n",
        "* Download the codebase (when using the host runtime)\n",
        "  1. Clone git repository and move to the specified branch\n",
        "  2. Install modules\n",
        "* Use GPU\n",
        "* Fix the random seed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIZJmuz8QFn_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if runtime == \"host\":\n",
        "    %cd /content\n",
        "    !rm -rf NL2Prog\n",
        "    !git clone $repository_url NL2Prog\n",
        "    %cd NL2Prog\n",
        "    !git checkout $branch_name\n",
        "    !pip install .\n",
        "# load tqdm\n",
        "!pip install --force https://github.com/chengs/tqdm/archive/colab.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rsyz7B0Ukxa7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "if device != -1:\n",
        "    torch.cuda.set_device(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwjlAkY1fR5j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "\n",
        "SEED_MAX = 2**32 - 1\n",
        "\n",
        "root_rng = np.random.RandomState(seed)\n",
        "random.seed(root_rng.randint(SEED_MAX))\n",
        "np.random.seed(root_rng.randint(SEED_MAX))\n",
        "torch.manual_seed(root_rng.randint(SEED_MAX))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oz7sdzxUi70b",
        "colab_type": "text"
      },
      "source": [
        "### Setup training\n",
        "* Load the dataset\n",
        "* Split the dataset into train, test, valid\n",
        "* Create and save encoder\n",
        "* Prepare dataset\n",
        "* Create model\n",
        "* Create optimizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7kdglcUjDTQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nl2prog.dataset.hearthstone import download\n",
        "dataset = download()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrFgwHCntjkt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nl2prog.utils.data import ListDataset, Entry\n",
        "train_raw_dataset = dataset[\"train\"]\n",
        "if num_train != 0:\n",
        "    train_raw_dataset = ListDataset(list(train_raw_dataset)[:num_train])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V0WsjTbjHOQ_",
        "colab": {}
      },
      "source": [
        "from torchnlp.encoders import LabelEncoder\n",
        "from nl2prog.encoders import ActionSequenceEncoder\n",
        "from nl2prog.utils.data import get_samples, get_words, get_characters\n",
        "from nl2prog.utils.python import tokenize_query, tokenize_token\n",
        "from nl2prog.language.action import code_to_action_sequence as to_seq, ActionOptions\n",
        "from nl2prog.language.python import parse\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "to_action_sequence = lambda x: to_seq(x, parse, tokenize=tokenize_token, options=ActionOptions(False, False))\n",
        "words = get_words(train_raw_dataset, tokenize_query)\n",
        "chars = get_characters(train_raw_dataset, tokenize_query)\n",
        "samples = get_samples(train_raw_dataset, tokenize_token, to_action_sequence)\n",
        "qencoder = LabelEncoder(words, word_threshold)\n",
        "cencoder = LabelEncoder(chars, 0)\n",
        "aencoder = ActionSequenceEncoder(samples, token_threshold)\n",
        "\n",
        "os.makedirs(output_dir_path, exist_ok=True)\n",
        "with open(os.path.join(output_dir_path, \"encoder.pickle\"), \"wb\") as file:\n",
        "    pickle.dump({\n",
        "        \"query_encoder\": qencoder,\n",
        "        \"character_encoder\": cencoder,\n",
        "        \"action_sequence_encoder\": aencoder\n",
        "    }, file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11mMmXAuutb9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nl2prog.utils.data.treegen import to_train_dataset\n",
        "train_dataset = to_train_dataset(train_raw_dataset, tokenize_query,\n",
        "                                 tokenize_token, to_action_sequence,\n",
        "                                 qencoder, cencoder, aencoder,\n",
        "                                 max_token_len, max_arity)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcAaeUZMtqSt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nl2prog.nn.treegen import TrainModel\n",
        "model = TrainModel(qencoder, cencoder, aencoder, max_token_len, max_arity,\n",
        "                   num_heads, num_nl_reader_blocks, num_ast_reader_blocks,\n",
        "                   num_decoder_blocks, hidden_size, feature_size, dropout)\n",
        "if device != -1:\n",
        "    model = model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NorsTPGntmw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install fairseq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ho3IgH4e04pi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import fairseq.optim as optim\n",
        "optimizer = optim.adafactor.Adafactor(model.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJw73TjO1CNc",
        "colab_type": "text"
      },
      "source": [
        "### Training Loop\n",
        "* Run training"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jAPAqZYz3A2p",
        "colab": {},
        "cellView": "both"
      },
      "source": [
        "from tqdm import tqdm_notebook as tqdm\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from nl2prog.utils import TopKModel\n",
        "from nl2prog.nn import Loss, Accuracy\n",
        "import nl2prog.nn.utils.rnn as nrnn\n",
        "from nl2prog.utils.data.treegen import collate_train_dataset\n",
        "\n",
        "\n",
        "def to_cuda(pad_seq):\n",
        "    pad_seq.data = pad_seq.data.cuda()\n",
        "    pad_seq.mask = pad_seq.mask.cuda()\n",
        "    return pad_seq\n",
        "\n",
        "model_dir_path = os.path.join(output_dir_path, \"models\")\n",
        "os.makedirs(model_dir_path, exist_ok=True)\n",
        "models = TopKModel(num_save_models, model_dir_path)\n",
        "loss_function = Loss()\n",
        "acc_function = Accuracy()\n",
        "\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "    loader = DataLoader(train_dataset, batch_size=batch_size,\n",
        "                        shuffle=True, num_workers=4,\n",
        "                        collate_fn=collate_train_dataset)\n",
        "    avg_loss = 0.0\n",
        "    avg_acc = 0.0\n",
        "    model.train()\n",
        "    for data, ground_truth in loader:\n",
        "        word_query = data[0]\n",
        "        char_query = data[1]\n",
        "        prev_action = data[2]\n",
        "        rule_prev_action = data[3]\n",
        "        depth = data[4]\n",
        "        matrix = data[5]\n",
        "        word_query = nrnn.pad_sequence(word_query, padding_value=-1)\n",
        "        char_query = nrnn.pad_sequence(char_query, padding_value=-1)\n",
        "        prev_action = nrnn.pad_sequence(prev_action, padding_value=-1)\n",
        "        rule_prev_action = \\\n",
        "            nrnn.pad_sequence(rule_prev_action, padding_value=-1)\n",
        "        depth = \\\n",
        "            nrnn.pad_sequence(depth).data.reshape(1, -1).permute(1, 0)\n",
        "        ground_truth = \\\n",
        "            nrnn.pad_sequence(ground_truth, padding_value=-1)\n",
        "        L = prev_action.data.shape[0]\n",
        "        matrix = [F.pad(m, (0, L - m.shape[0], 0, L - m.shape[1]))\n",
        "                  for m in matrix]\n",
        "        matrix = nrnn.pad_sequence(matrix).data.permute(1, 0, 2)\n",
        "        if device != -1:\n",
        "            to_cuda(word_query)\n",
        "            to_cuda(char_query)\n",
        "            to_cuda(prev_action)\n",
        "            to_cuda(rule_prev_action)\n",
        "            to_cuda(ground_truth)\n",
        "            depth = depth.cuda()\n",
        "            matrix = matrix.cuda()\n",
        "\n",
        "        rule_prob, token_prob, copy_prob = model(\n",
        "            word_query, char_query, prev_action, rule_prev_action,\n",
        "            depth, matrix)\n",
        "        loss = loss_function(rule_prob, token_prob, copy_prob, ground_truth)\n",
        "        with torch.no_grad():\n",
        "            acc = acc_function(rule_prob, token_prob, copy_prob, ground_truth)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        avg_loss += loss.item() / len(loader)\n",
        "        avg_acc += acc.item() / len(loader)\n",
        "    print(epoch, avg_loss, avg_acc)\n",
        "    models.save(avg_acc, str(epoch), model)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}