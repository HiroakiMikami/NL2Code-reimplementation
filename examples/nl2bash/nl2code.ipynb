{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NL2Code nl2bash train",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "yje9hqtcUQ_f"
      },
      "outputs": [],
      "source": [
        "### Initialization\n",
        "* Check whether the runtime is host or local.\n",
        "* Mount Google Drive when using the host runtime."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "FwqGy_GyUQnw"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  from google.colab import auth\n",
        "  auth.authenticate_user()\n",
        "  from google.colab import drive\n",
        "  drive.mount('/gdrive')\n",
        "  runtime = \"host\"\n",
        "except:\n",
        "  runtime = \"local\""
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "_S457sT6QMUr"
      },
      "outputs": [],
      "source": [
        "### Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "2LYvG4iCQUwh"
      },
      "outputs": [],
      "source": [
        "#@title Parameters\n",
        "#@markdown |Name            |Description|\n",
        "#@markdown |:---            |:---|\n",
        "#@markdown |`seed`|The random seed|\n",
        "seed = 20367 #@param {type: \"number\"}\n",
        "\n",
        "#@markdown ### `nl2prog` Repositories\n",
        "#@markdown |Name            |Description|\n",
        "#@markdown |:---            |:---|\n",
        "#@markdown |`repository_url`|The URL of `nl2prog` git repository (enabled only in the host runtime)|\n",
        "#@markdown |`branch_name`   |The branch name (enabled only in the host runtime)|\n",
        "repository_url = \"https://github.com/HiroakiMikami/NL2Prog\" #@param {type: \"string\"}\n",
        "branch_name = \"master\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown ### Dataset Settings\n",
        "#@markdown |Name               |Description|\n",
        "#@markdown |:---               |:---|\n",
        "#@markdown |`max_action_length`|The maximum action length|\n",
        "#@markdown |`word_threshold`   ||\n",
        "#@markdown |`token_threshold`  ||\n",
        "max_action_length = 350 #@param {type: \"number\"}\n",
        "word_threshold = 3 #@param {type: \"number\"}\n",
        "token_threshold = 0 #@param {type: \"number\"}\n",
        "\n",
        "#@markdown ### Model Parameters\n",
        "#@markdown |Name                     |Description|\n",
        "#@markdown |:---                     |:---|\n",
        "#@markdown |`embedding_dim`          |The dimension of word, token, and rule embeddings|\n",
        "#@markdown |`node_type_embedding_dim`|The dimension of node type embedding dim|\n",
        "#@markdown |`lstm_state_size`        |The size of LSTM state|\n",
        "#@markdwon |`hidden_state_size`      |The size of attention hidden state|\n",
        "embedding_dim = 128 #@param {type: \"number\"}\n",
        "node_type_embedding_dim = 64 #@param {type: \"number\"}\n",
        "lstm_state_size = 256 #@param {type: \"number\"}\n",
        "hidden_state_size = 50 #@param {type: \"number\"}\n",
        "\n",
        "#@markdown ### Training Settings\n",
        "#@markdown |Name        |Description|\n",
        "#@markdown |:---        |:---|\n",
        "#@markdown |`batch_size`|The minibatch size|\n",
        "#@markdown |`dropout`   |The probability of dropout|\n",
        "#@markdown |`num_epochs`|The numer of epoch|\n",
        "#@markdown |`num_train` |The number of entries used for training|\n",
        "batch_size = 10 #@param {type: \"number\"}\n",
        "dropout = 0.2 #@param {type: \"number\"}\n",
        "num_epochs = 50 #@param {type: \"number\"}\n",
        "num_train =  0#@param {type: \"number\"}\n",
        "\n",
        "\n",
        "#@markdown ### Evaluation Settings\n",
        "#@markdown |Name                 |Description|\n",
        "#@markdown |:---                 |:---|\n",
        "#@markdown |`beam_size`          |The beam size|\n",
        "#@markdown |`evaluation_interval`|The number of epochs between two evaluation|\n",
        "beam_size = 15 #@param {type: \"number\"}\n",
        "evaluation_interval = 5 #@param {type: \"number\"}\n",
        "\n",
        "#@markdown ### Other Settings\n",
        "#@markdown |Name    |Description|\n",
        "#@markdown |:---    |:---|\n",
        "#@markdown |`device`|The id of GPU. `-1` means that CPU is used.|\n",
        "device = 0 #@param {type: \"number\"}\n",
        "\n",
        "#@markdown ### Filepathes\n",
        "#@markdown |Name                 |Description|\n",
        "#@markdown |:---                 |:---|\n",
        "#@markdown |`output_dir_path`    |The directory of the directory that will contain the training results.|\n",
        "#@markdown |`checkpoint_dir_path`|The directory of the directory that will contain the checkpoints.|\n",
        "output_dir_path = \"/gdrive/My Drive/NL2Code/nl2bash/result/\" #@param {type: \"string\"}\n",
        "checkpoint_dir_path = \"/gdrive/My Drive/NL2Code/nl2bash/checkpoint/\" #@param {type: \"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "_BembldCdOO1"
      },
      "outputs": [],
      "source": [
        "### Setup\n",
        "* Download the codebase (when using the host runtime)\n",
        "  1. Clone git repository and move to the specified branch\n",
        "  2. Install modules\n",
        "* Use GPU\n",
        "* Fix the random seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "FIZJmuz8QFn_"
      },
      "outputs": [],
      "source": [
        "if runtime == \"host\":\n",
        "    %cd /content\n",
        "    !rm -rf NL2Prog\n",
        "    #![ ! -e NL2Code ] && git clone $repository_url NL2Prog\n",
        "    !gcloud source repos clone NL2Prog --project development-environment-192405\n",
        "    !mv NL2Prog NL2Prog\n",
        "    %cd NL2Prog\n",
        "    #!git checkout $branch_name\n",
        "    !git checkout origin/feature/treegen\n",
        "    !pip install -e .\n",
        "    !pip install -e . \".[examples]\"\n",
        "# load tqdm\n",
        "!pip install --force https://github.com/chengs/tqdm/archive/colab.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Rsyz7B0Ukxa7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "if device != -1:\n",
        "    torch.cuda.set_device(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "GwjlAkY1fR5j"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "\n",
        "SEED_MAX = 2**32 - 1\n",
        "\n",
        "root_rng = np.random.RandomState(seed)\n",
        "random.seed(root_rng.randint(SEED_MAX))\n",
        "np.random.seed(root_rng.randint(SEED_MAX))\n",
        "torch.manual_seed(root_rng.randint(SEED_MAX))"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "Oz7sdzxUi70b"
      },
      "outputs": [],
      "source": [
        "### Setup training\n",
        "* Load the dataset\n",
        "* Split the dataset into train, test, valid\n",
        "* Create and save encoder\n",
        "* Prepare dataset\n",
        "* Create model\n",
        "* Create optimizer\n",
        "* Prepare evaluation\n",
        "* Load checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "h7kdglcUjDTQ"
      },
      "outputs": [],
      "source": [
        "from nl2prog.dataset.nl2bash import download\n",
        "dataset = download(\"/content/NL2Code/bin/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "IrFgwHCntjkt"
      },
      "outputs": [],
      "source": [
        "from nl2prog.utils.data import ListDataset\n",
        "train_raw_dataset = dataset[\"train\"]\n",
        "test_raw_dataset = dataset[\"test\"]\n",
        "val_raw_dataset = dataset[\"valid\"]\n",
        "if num_train != 0:\n",
        "    train_raw_dataset = ListDataset(list(train_raw_dataset)[:num_train])\n",
        "    test_raw_dataset = ListDataset(list(train_raw_dataset)[:num_train])\n",
        "    val_raw_dataset = ListDataset(list(train_raw_dataset)[:num_train])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "V0WsjTbjHOQ_"
      },
      "outputs": [],
      "source": [
        "from nl2prog.utils.data.nl2code import Encoder\n",
        "from nl2prog.utils.data import get_samples\n",
        "from nl2prog.utils.nl2code import to_action_sequence as to_seq\n",
        "from nl2prog.dataset.nl2bash.nl2code import tokenize_query, tokenize_token\n",
        "from nl2prog.language.bash import parse\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "to_action_sequence = lambda x: to_seq(x, parse, tokenize_token)\n",
        "!mkdir -p \"$output_dir_path\"\n",
        "samples = get_samples(train_raw_dataset, tokenize_query, tokenize_token,\n",
        "                      to_action_sequence)\n",
        "encoder = Encoder(samples, word_threshold, token_threshold)\n",
        "with open(os.path.join(output_dir_path, \"encoder.pickle\"), \"wb\") as file:\n",
        "    pickle.dump(encoder, file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "11mMmXAuutb9"
      },
      "outputs": [],
      "source": [
        "from nl2prog.utils.data.nl2code import to_train_dataset, to_eval_dataset\n",
        "train_dataset = to_train_dataset(train_raw_dataset, tokenize_query, tokenize_token, to_action_sequence, encoder)\n",
        "test_dataset = to_eval_dataset(test_raw_dataset)\n",
        "valid_dataset = to_eval_dataset(val_raw_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "QcAaeUZMtqSt"
      },
      "outputs": [],
      "source": [
        "from nl2prog.nn.nl2code import TrainModel\n",
        "model = TrainModel(encoder, embedding_dim, node_type_embedding_dim,\n",
        "                   lstm_state_size, hidden_state_size,\n",
        "                   dropout)\n",
        "if device != -1:\n",
        "    model = model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ho3IgH4e04pi"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "optimizer = optim.Adam(model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "puzSJ3lbdt9Y"
      },
      "outputs": [],
      "source": [
        "import nl2prog.nn.utils.rnn as nrnn\n",
        "from nl2prog.utils import synthesize as _synthesize\n",
        "from nl2prog.utils.nl2code import BeamSearchSynthesizer\n",
        "from nl2prog.language.bash import is_subtype, parse, unparse\n",
        "from nl2prog.metrics import Accuracy, Bleu\n",
        "\n",
        "from typing import List\n",
        "\n",
        "def encode_query(query: List[str]):\n",
        "    x = encoder.annotation_encoder.batch_encode(query)\n",
        "    if device != -1:\n",
        "        x = x.cuda()\n",
        "    embedding =  model.encoder(nrnn.pad_sequence([x]))\n",
        "    embedding = embedding.data\n",
        "    return embedding.view(len(query), -1)\n",
        "\n",
        "\n",
        "synthesizer = BeamSearchSynthesizer(beam_size, model.predictor,\n",
        "                                    encoder.action_sequence_encoder, is_subtype,\n",
        "                                    max_steps=max_action_length)\n",
        "\n",
        "def synthesize(query: str):\n",
        "    return _synthesize(query, encode_query, synthesizer)\n",
        "\n",
        "accuracy = Accuracy(parse, unparse)\n",
        "bleu = Bleu(parse, unparse)\n",
        "metrics = { \"accuracy\": accuracy, \"bleu\": bleu }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "DgE1-G6poK7S"
      },
      "outputs": [],
      "source": [
        "!mkdir -p \"$checkpoint_dir_path\"\n",
        "checkpoint_path = os.path.join(checkpoint_dir_path, \"checkpoint.pickle\")\n",
        "if os.path.exists(checkpoint_path):\n",
        "    print(\"Load checkpoint: {}\".format(checkpoint_path))\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=\"cpu\")\n",
        "    start_epoch = checkpoint[\"epoch\"]\n",
        "    model.load_state_dict(checkpoint[\"model\"])\n",
        "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
        "else:\n",
        "    start_epoch = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "sJw73TjO1CNc"
      },
      "outputs": [],
      "source": [
        "### Training Loop\n",
        "* Run training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "jAPAqZYz3A2p"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.utils.rnn as rnn\n",
        "from nl2prog.utils import evaluate\n",
        "from nl2prog.nn.nl2code import Loss, Accuracy\n",
        "import nl2prog.nn.utils.rnn as nrnn\n",
        "from nl2prog.utils.data.nl2code import collate_train_dataset\n",
        "\n",
        "\n",
        "loss_function = Loss()\n",
        "acc_function = Accuracy()\n",
        "best_score = -1\n",
        "for epoch in range(start_epoch, num_epochs):\n",
        "    loader = DataLoader(train_dataset, batch_size=batch_size,\n",
        "                        shuffle=True,\n",
        "                        num_workers=4,\n",
        "                        collate_fn=collate_train_dataset)\n",
        "    avg_loss = 0.0\n",
        "    model.train()\n",
        "    for i, (query, action, prev_action) in enumerate(loader):\n",
        "        query = rnn.pack_sequence(query, enforce_sorted=False)\n",
        "        action = rnn.pack_sequence(action, enforce_sorted=False)\n",
        "        prev_action_train = [x[:-1] for x in prev_action]\n",
        "        action_ground_truth = [x[1:] for x in prev_action]\n",
        "        prev_action_train = rnn.pack_sequence(prev_action_train, enforce_sorted=False)\n",
        "        action_ground_truth = rnn.pack_sequence(action_ground_truth, enforce_sorted=False)\n",
        "        if device != -1:\n",
        "            query = query.cuda()\n",
        "            action = action.cuda()\n",
        "            prev_action_train = prev_action_train.cuda()\n",
        "            action_ground_truth = action_ground_truth.cuda()\n",
        "        query = nrnn.pad_packed_sequence(query, padding_value=-1)\n",
        "        action = nrnn.pad_packed_sequence(action, padding_value=-1)\n",
        "        prev_action_train = nrnn.pad_packed_sequence(prev_action_train, padding_value=-1)\n",
        "        action_ground_truth = nrnn.pad_packed_sequence(action_ground_truth, padding_value=-1)\n",
        "\n",
        "        rule_prob, token_prob, copy_prob, _, _ = model(query, action, prev_action_train)\n",
        "        loss = loss_function(rule_prob, token_prob, copy_prob, action_ground_truth)\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        step = epoch * len(train_dataset) + i * batch_size\n",
        "        l = loss.cpu().detach().numpy()\n",
        "        avg_loss += l / len(loader)\n",
        "    print(epoch, avg_loss)\n",
        "    checkpoint = {\n",
        "        \"model\": model.state_dict(),\n",
        "        \"optimizer\": optimizer.state_dict(),\n",
        "        \"epoch\": epoch + 1\n",
        "    }\n",
        "    torch.save(checkpoint, checkpoint_path)\n",
        "\n",
        "    # Evaluate test dataset\n",
        "    if (epoch + 1) % evaluation_interval == 0:\n",
        "        model.eval()\n",
        "        result = evaluate(tqdm(test_dataset), synthesize, top_n=[1, 3], metrics=metrics)\n",
        "        print(epoch, result.metrics)\n",
        "        score = result.metrics[3][\"bleu\"]\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            torch.save(model.state_dict(), os.path.join(output_dir_path, \"best_model.pickle\"))\n",
        "\n",
        "if best_score < 0:\n",
        "    torch.save(model.state_dict(), os.path.join(output_dir_path, \"best_model.pickle\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "toeP4RGEeK1b"
      },
      "outputs": [],
      "source": [
        "### Run Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "BAjEaEWYeKGF"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm_notebook as tqdm\n",
        "import os\n",
        "import pickle\n",
        "import torch\n",
        "import torch.nn.utils.rnn as rnn\n",
        "import nl2prog.nn.utils.rnn as nrnn\n",
        "from nl2prog.utils import evaluate\n",
        "\n",
        "# Validate the model\n",
        "model.load_state_dict(torch.load(os.path.join(output_dir_path, \"best_model.pickle\")))\n",
        "model.eval()\n",
        "result = evaluate(tqdm(valid_dataset), synthesize, top_n=[1, 3], metrics=metrics)\n",
        "print(result.metrics)\n",
        "with open(os.path.join(output_dir_path, \"validation_results.pickle\"), \"wb\") as file:\n",
        "    pickle.dump(result.results, file)\n"
      ]
    }
  ]
}