normalize_dataset:
  type: mlprogram.utils.transform.NormalizeGroundTruth
  normalize:
    type: mlprogram.functools.Sequence
    funcs:
      type: collections.OrderedDict
      items:
        - - parse
          - "@/parser.parse"
        - - unparse
          - "@/parser.unparse"

train_dataset: "@/dataset.train"
test_dataset:
  type: mlprogram.utils.data.transform
  dataset: "@/dataset.test"
  transform: "@/normalize_dataset"
valid_dataset:
  type: mlprogram.utils.data.transform
  dataset: "@/dataset.valid"
  transform: "@/normalize_dataset"

encoder:
  word_encoder:
    type: with_file_cache
    path:
      type: os.path.join
      args:
        - "@/output_dir"
        - "word_encoder.pt"
    config:
      type: torchnlp.encoders.LabelEncoder
      sample:
        type: mlprogram.utils.data.get_words
        dataset: "@/train_dataset"
        extract_reference:
          type: mlprogram.datasets.nl2bash.TokenizeQuery
      min_occurrences: 3
  action_sequence_encoder:
    type: with_file_cache
    path:
      type: os.path.join
      args:
        - "@/output_dir"
        - "action_sequence_encoder.pt"
    config:
      type: mlprogram.encoders.ActionSequenceEncoder
      samples:
        type: mlprogram.utils.data.get_samples
        dataset: "@/train_dataset"
        parser: "@/parser"
      token_threshold: 0

action_sequence_reader:
  type: mlprogram.nn.nl2code.ActionSequenceReader
  num_rules: "@/encoder.action_sequence_encoder._rule_encoder.vocab_size"
  num_tokens: "@/encoder.action_sequence_encoder._token_encoder.vocab_size"
  num_node_types: "@/encoder.action_sequence_encoder._node_type_encoder.vocab_size"
  node_type_embedding_size: "@/node_type_embedding_size"
  embedding_size: "@/embedding_size"
model:
  type: torch.share_memory_
  model:
    type: torch.nn.Sequential
    modules:
      type: collections.OrderedDict
      items:
        - - "encoder"
          - type: mlprogram.nn.nl2code.NLReader
            num_words: "@/encoder.word_encoder.vocab_size"
            embedding_dim: "@/embedding_size"
            hidden_size: "@/hidden_size"
            dropout: "@/dropout"
        - - "decoder"
          - type: torch.nn.Sequential
            modules:
              type: collections.OrderedDict
              items:
                - - "action_sequence_reader"
                  - "@/action_sequence_reader"
                - - "decoder"
                  - type: mlprogram.nn.nl2code.Decoder
                    query_size: "@/hidden_size"
                    input_size:
                      type: add
                      x:
                        type: mul
                        x: 2
                        y: "@/embedding_size"
                      y: "@/node_type_embedding_size"
                    hidden_size: "@/hidden_size"
                    att_hidden_size: "@/attr_hidden_size"
                    dropout: "@/dropout"
                - - "predictor"
                  - type: mlprogram.nn.nl2code.Predictor
                    reader: "@/action_sequence_reader"
                    embedding_size: "@/embedding_size"
                    query_size: "@/hidden_size"
                    hidden_size: "@/hidden_size"
                    att_hidden_size: "@/attr_hidden_size"

collate:
  type: mlprogram.utils.data.Collate
  device: "@/device"
  word_nl_query:
    type: mlprogram.utils.data.CollateOptions
    use_pad_sequence: true
    dim: 0
    padding_value: -1
  nl_query_features:
    type: mlprogram.utils.data.CollateOptions
    use_pad_sequence: true
    dim: 0
    padding_value: -1
  reference_features:
    type: mlprogram.utils.data.CollateOptions
    use_pad_sequence: true
    dim: 0
    padding_value: -1
  actions:
    type: mlprogram.utils.data.CollateOptions
    use_pad_sequence: true
    dim: 0
    padding_value: -1
  previous_actions:
    type: mlprogram.utils.data.CollateOptions
    use_pad_sequence: true
    dim: 0
    padding_value: -1
  previous_action_rules:
    type: mlprogram.utils.data.CollateOptions
    use_pad_sequence: true
    dim: 0
    padding_value: -1
  history:
    type: mlprogram.utils.data.CollateOptions
    use_pad_sequence: false
    dim: 1
    padding_value: 0
  hidden_state:
    type: mlprogram.utils.data.CollateOptions
    use_pad_sequence: false
    dim: 0
    padding_value: 0
  state:
    type: mlprogram.utils.data.CollateOptions
    use_pad_sequence: false
    dim: 0
    padding_value: 0
  ground_truth_actions:
    type: mlprogram.utils.data.CollateOptions
    use_pad_sequence: true
    dim: 0
    padding_value: -1

synthesizer:
  type: mlprogram.synthesizers.BeamSearch
  beam_size: "@/beam_size"
  max_step_size: "@/max_step_size"
  sampler:
    type: mlprogram.samplers.transform
    sampler:
      type: mlprogram.samplers.ActionSequenceSampler
      encoder: "@/encoder.action_sequence_encoder"
      is_subtype:
        type: mlprogram.languages.bash.IsSubtype
      transform_input:
        type: mlprogram.utils.transform.nl2code.TransformQuery
        extract_reference:
          type: mlprogram.datasets.nl2bash.TokenizeQuery
        word_encoder: "@/encoder.word_encoder"
      transform_action_sequence:
        type: mlprogram.utils.transform.nl2code.TransformActionSequence
        action_sequence_encoder: "@/encoder.action_sequence_encoder"
        train: false
      collate: "@/collate"
      module: "@/model"
    transform: "@/parser.unparse"

metrics:
  accuracy:
    type: mlprogram.metrics.Accuracy
  bleu:
    type: mlprogram.metrics.Bleu
