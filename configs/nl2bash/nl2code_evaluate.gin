# device
torch.device.type_str = "cuda"
torch.device.index    = 0

# Dataset
dataset/nl2prog.gin.workspace.put.value = @nl2prog.dataset.nl2bash.download()
dataset/nl2prog.gin.workspace.get.key   = "dataset"

# ActionOptions
nl2prog.ast.action.ActionOptions.retain_variadic_fields = True
nl2prog.ast.action.ActionOptions.split_non_terminal     = True

# to_action_sequence
nl2prog.ast.action.code_to_action_sequence.parse    = @nl2prog.language.bash.parse
nl2prog.ast.action.code_to_action_sequence.tokenize = @nl2prog.dataset.nl2bash.tokenize_token
nl2prog.ast.action.code_to_action_sequence.options  = @nl2prog.ast.action.ActionOptions()

# Encoder
word_encoder/nl2prog.gin.workspace.get.key             = "query_encoder"
action_sequence_encoder/nl2prog.gin.workspace.get.key  = "action_sequence_encoder"

# Transform
nl2prog.utils.transform.nl2code.TransformQuery.extract_query               = @nl2prog.dataset.nl2bash.tokenize_query
nl2prog.utils.transform.nl2code.TransformQuery.word_encoder                = @word_encoder/nl2prog.gin.workspace.get()
nl2prog.utils.transform.nl2code.TransformEvaluator.action_sequence_encoder = @action_sequence_encoder/nl2prog.gin.workspace.get()
nl2prog.utils.transform.nl2code.TransformEvaluator.train                   = False

# Model
nl2prog.nn.nl2code.TrainModel.query_encoder           = @word_encoder/nl2prog.gin.workspace.get()
nl2prog.nn.nl2code.TrainModel.action_sequence_encoder = @action_sequence_encoder/nl2prog.gin.workspace.get()
nl2prog.nn.nl2code.TrainModel.embedding_dim           = 128
nl2prog.nn.nl2code.TrainModel.node_type_embedding_dim = 64
nl2prog.nn.nl2code.TrainModel.lstm_state_size         = 256
nl2prog.nn.nl2code.TrainModel.hidden_state_size       = 50
nl2prog.nn.nl2code.TrainModel.dropout                 = 0.2

# Collate
nl2prog.utils.data.nl2code.CollateInput.device          = @torch.device()
nl2prog.utils.data.nl2code.CollateActionSequence.device = @torch.device()
nl2prog.utils.data.nl2code.CollateState.device          = @torch.device()
nl2prog.utils.data.CollateNlFeature.device              = @torch.device()

# Synthesizer
nl2prog.utils.CommonBeamSearchSynthesizer.create.beam_size               = 15
nl2prog.utils.CommonBeamSearchSynthesizer.create.transform_input         = @nl2prog.utils.transform.nl2code.TransformQuery()
nl2prog.utils.CommonBeamSearchSynthesizer.create.transform_evaluator     = @nl2prog.utils.transform.nl2code.TransformEvaluator()
nl2prog.utils.CommonBeamSearchSynthesizer.create.collate_input           = @nl2prog.utils.data.nl2code.CollateInput()
nl2prog.utils.CommonBeamSearchSynthesizer.create.collate_action_sequence = @nl2prog.utils.data.nl2code.CollateActionSequence()
nl2prog.utils.CommonBeamSearchSynthesizer.create.collate_query           = @nl2prog.utils.data.collate_none
nl2prog.utils.CommonBeamSearchSynthesizer.create.collate_state           = @nl2prog.utils.data.nl2code.CollateState()
nl2prog.utils.CommonBeamSearchSynthesizer.create.collate_nl_feature      = @nl2prog.utils.data.CollateNlFeature()
nl2prog.utils.CommonBeamSearchSynthesizer.create.collate_other_feature   = @nl2prog.utils.data.collate_none
nl2prog.utils.CommonBeamSearchSynthesizer.create.split_states            = @nl2prog.utils.data.nl2code.split_states
nl2prog.utils.CommonBeamSearchSynthesizer.create.model                   = @nl2prog.nn.nl2code.TrainModel()
nl2prog.utils.CommonBeamSearchSynthesizer.create.action_sequence_encoder = @action_sequence_encoder/nl2prog.gin.workspace.get()
nl2prog.utils.CommonBeamSearchSynthesizer.create.is_subtype              = @nl2prog.language.bash.is_subtype
nl2prog.utils.CommonBeamSearchSynthesizer.create.options                 = @nl2prog.ast.action.ActionOptions()
nl2prog.utils.CommonBeamSearchSynthesizer.create.device                  = @torch.device()
nl2prog.utils.CommonBeamSearchSynthesizer.create.max_steps               = 350
synthesizer/nl2prog.gin.workspace.put.value                              = @nl2prog.utils.CommonBeamSearchSynthesizer.create()

# Metrics
nl2prog.metrics.Accuracy.parse   = @nl2prog.language.bash.parse
nl2prog.metrics.Accuracy.unparse = @nl2prog.language.bash.unparse
nl2prog.metrics.Bleu.parse       = @nl2prog.language.bash.parse
nl2prog.metrics.Bleu.unparse     = @nl2prog.language.bash.unparse

# Task
entrypoint.task                                  = @nl2prog.gin.nl2prog.evaluate
nl2prog.gin.nl2prog.evaluate.dataset_key         = "dataset"
nl2prog.gin.nl2prog.evaluate.synthesizer_key     = "synthesizer"
nl2prog.gin.nl2prog.evaluate.encoder_keys        = ["query_encoder", "action_sequence_encoder"]
nl2prog.gin.nl2prog.evaluate.input_dir           = "output/output"
nl2prog.gin.nl2prog.evaluate.workspace_dir       = "output/workspace"
nl2prog.gin.nl2prog.evaluate.output_dir          = "output/output"
nl2prog.gin.nl2prog.evaluate.prepare_dataset     = @dataset/nl2prog.gin.workspace.put
nl2prog.gin.nl2prog.evaluate.prepare_synthesizer = @synthesizer/nl2prog.gin.workspace.put
nl2prog.gin.nl2prog.evaluate.metrics             = {"accuracy": @nl2prog.metrics.Accuracy(), "bleu": @nl2prog.metrics.Bleu()}
nl2prog.gin.nl2prog.evaluate.main_metric         = (1, "bleu")
nl2prog.gin.nl2prog.evaluate.top_n               = [1]
nl2prog.gin.nl2prog.evaluate.device              = @torch.device()
