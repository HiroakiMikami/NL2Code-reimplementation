# device
torch.device.type_str = "cuda"
torch.device.index    = 0

# Dataset
dataset/nl2prog.gin.workspace.put.value = @nl2prog.dataset.hearthstone.download()
dataset/nl2prog.gin.workspace.get.key   = "dataset"

# ActionOptions
nl2prog.ast.action.ActionOptions.retain_variadic_fields = False
nl2prog.ast.action.ActionOptions.split_non_terminal     = False

# to_action_sequence
nl2prog.ast.action.code_to_action_sequence.parse    = @nl2prog.language.python.parse
nl2prog.ast.action.code_to_action_sequence.tokenize = @nl2prog.utils.python.tokenize_token
nl2prog.ast.action.code_to_action_sequence.options  = @nl2prog.ast.action.ActionOptions()

# Encoder
train_dataset/nl2prog.gin.get_key.key                  = "train"
train_dataset/nl2prog.gin.get_key.target               = @dataset/nl2prog.gin.workspace.get()
nl2prog.gin.treegen.prepare_encoder.dataset            = @train_dataset/nl2prog.gin.get_key()
nl2prog.gin.treegen.prepare_encoder.word_threshold     = 3
nl2prog.gin.treegen.prepare_encoder.char_threshold     = 0
nl2prog.gin.treegen.prepare_encoder.token_threshold    = 0
nl2prog.gin.treegen.prepare_encoder.parse              = @nl2prog.language.python.parse
nl2prog.gin.treegen.prepare_encoder.to_action_sequence = @nl2prog.ast.action.code_to_action_sequence
nl2prog.gin.treegen.prepare_encoder.extract_query      = @nl2prog.utils.python.tokenize_query
nl2prog.gin.treegen.prepare_encoder.tokenize_token     = @nl2prog.utils.python.tokenize_token
word_encoder/nl2prog.gin.workspace.get.key             = "query_encoder"
char_encoder/nl2prog.gin.workspace.get.key             = "char_encoder"
action_sequence_encoder/nl2prog.gin.workspace.get.key  = "action_sequence_encoder"

# Transform
nl2prog.utils.transform.TransformDataset.transform_input                   = @nl2prog.utils.transform.treegen.TransformQuery()
nl2prog.utils.transform.treegen.TransformQuery.extract_query               = @nl2prog.utils.python.tokenize_query
nl2prog.utils.transform.treegen.TransformQuery.word_encoder                = @word_encoder/nl2prog.gin.workspace.get()
nl2prog.utils.transform.treegen.TransformQuery.char_encoder                = @char_encoder/nl2prog.gin.workspace.get()
nl2prog.utils.transform.treegen.TransformQuery.max_word_length             = 128
nl2prog.utils.transform.TransformDataset.transform_code                    = @nl2prog.utils.transform.TransformCode()
nl2prog.utils.transform.TransformCode.to_action_sequence                   = @nl2prog.ast.action.code_to_action_sequence
nl2prog.utils.transform.TransformDataset.transform_evaluator               = @nl2prog.utils.transform.treegen.TransformEvaluator()
nl2prog.utils.transform.treegen.TransformEvaluator.action_sequence_encoder = @action_sequence_encoder/nl2prog.gin.workspace.get()
nl2prog.utils.transform.treegen.TransformEvaluator.max_arity               = 128
nl2prog.utils.transform.treegen.TransformEvaluator.max_depth               = 128
nl2prog.utils.transform.treegen.TransformEvaluator.train                   = True
nl2prog.utils.transform.TransformDataset.transform_ground_truth            = @nl2prog.utils.transform.TransformGroundTruth()
nl2prog.utils.transform.TransformGroundTruth.action_sequence_encoder       = @action_sequence_encoder/nl2prog.gin.workspace.get()

# Model
nl2prog.nn.treegen.TrainModel.query_encoder                        = @word_encoder/nl2prog.gin.workspace.get()
nl2prog.nn.treegen.TrainModel.char_encoder                         = @char_encoder/nl2prog.gin.workspace.get()
nl2prog.nn.treegen.TrainModel.action_sequence_encoder              = @action_sequence_encoder/nl2prog.gin.workspace.get()
nl2prog.nn.treegen.TrainModel.max_token_len                        = 128
nl2prog.nn.treegen.TrainModel.max_arity                            = 128
nl2prog.nn.treegen.TrainModel.max_depth                            = 128
nl2prog.nn.treegen.TrainModel.num_heads                            = 8
nl2prog.nn.treegen.TrainModel.num_nl_reader_blocks                 = 6
nl2prog.nn.treegen.TrainModel.num_action_sequence_reader_blocks    = 6
nl2prog.nn.treegen.TrainModel.num_decoder_blocks                   = 6
nl2prog.nn.treegen.TrainModel.hidden_size                          = 256
nl2prog.nn.treegen.TrainModel.feature_size                         = 1024
nl2prog.nn.treegen.TrainModel.dropout                              = 0.15
model/nl2prog.gin.workspace.put.value                              = @nl2prog.nn.treegen.TrainModel()
model/nl2prog.gin.workspace.get.key                                = "model"

# Collate
nl2prog.utils.data.Collate.collate_input                = @nl2prog.utils.data.treegen.CollateInput()
nl2prog.utils.data.Collate.collate_action_sequence      = @nl2prog.utils.data.treegen.CollateActionSequence()
nl2prog.utils.data.Collate.collate_query                = @nl2prog.utils.data.treegen.CollateQuery()
nl2prog.utils.data.Collate.collate_ground_truth         = @nl2prog.utils.data.CollateGroundTruth()
nl2prog.utils.data.treegen.CollateInput.device          = @torch.device()
nl2prog.utils.data.treegen.CollateActionSequence.device = @torch.device()
nl2prog.utils.data.treegen.CollateQuery.device          = @torch.device()
nl2prog.utils.data.CollateGroundTruth.device            = @torch.device()

# Optimizer
nl2prog.gin.optimizer.create_optimizer.optimizer_cls = @fairseq.optim.Adafactor
nl2prog.gin.optimizer.create_optimizer.model         = @model/nl2prog.gin.workspace.get()
optimizer/nl2prog.gin.workspace.put.value            = @nl2prog.gin.optimizer.create_optimizer()

# Task
entrypoint.task                              = @nl2prog.gin.nl2prog.train
nl2prog.gin.nl2prog.train.dataset_key        = "dataset"
nl2prog.gin.nl2prog.train.model_key          = "model"
nl2prog.gin.nl2prog.train.optimizer_key      = "optimizer"
nl2prog.gin.nl2prog.train.encoder_keys       = ["query_encoder", "char_encoder", "action_sequence_encoder"]
nl2prog.gin.nl2prog.train.workspace_dir      = "output/workspace"
nl2prog.gin.nl2prog.train.output_dir         = "output/output"
nl2prog.gin.nl2prog.train.prepare_dataset    = @dataset/nl2prog.gin.workspace.put
nl2prog.gin.nl2prog.train.prepare_encoder    = @nl2prog.gin.treegen.prepare_encoder
nl2prog.gin.nl2prog.train.prepare_model      = @model/nl2prog.gin.workspace.put
nl2prog.gin.nl2prog.train.prepare_optimizer  = @optimizer/nl2prog.gin.workspace.put
nl2prog.gin.nl2prog.train.transform_cls      = @nl2prog.utils.transform.TransformDataset
nl2prog.gin.nl2prog.train.loss_fn            = @nl2prog.nn.Loss()
nl2prog.gin.nl2prog.train.score_fn           = @nl2prog.nn.Accuracy()
nl2prog.gin.nl2prog.train.collate_fn         = @nl2prog.utils.data.Collate()
nl2prog.gin.nl2prog.train.batch_size         = 1
nl2prog.gin.nl2prog.train.num_epochs         = 50
nl2prog.gin.nl2prog.train.device             = @torch.device()
