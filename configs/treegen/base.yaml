normalize_dataset:
  type: mlprogram.utils.transform.NormalizeGroundTruth
  normalize:
    type: mlprogram.functools.Sequence
    funcs:
      type: collections.OrderedDict
      items:
        - - parse
          - "@/parser.parse"
        - - unparse
          - "@/parser.unparse"

train_dataset: "@/dataset.train"
test_dataset:
  type: mlprogram.utils.data.transform
  dataset: "@/dataset.test"
  transform: "@/normalize_dataset"
valid_dataset:
  type: mlprogram.utils.data.transform
  dataset: "@/dataset.valid"
  transform: "@/normalize_dataset"

encoder:
  word_encoder:
    type: with_file_cache
    path:
      type: os.path.join
      args:
        - "@/output_dir"
        - "word_encoder.pt"
    config:
      type: torchnlp.encoders.LabelEncoder
      sample:
        type: mlprogram.utils.data.get_words
        dataset: "@/train_dataset"
        extract_reference: "@/extract_reference"
      min_occurrences: "@/params.word_threshold"
  char_encoder:
    type: with_file_cache
    path:
      type: os.path.join
      args:
        - "@/output_dir"
        - "char_encoder.pt"
    config:
      type: torchnlp.encoders.LabelEncoder
      sample:
        type: mlprogram.utils.data.get_characters
        dataset: "@/train_dataset"
        extract_reference: "@/extract_reference"
      min_occurrences: 0
  action_sequence_encoder:
    type: with_file_cache
    path:
      type: os.path.join
      args:
        - "@/output_dir"
        - "action_sequence_encoder.pt"
    config:
      type: mlprogram.encoders.ActionSequenceEncoder
      samples:
        type: mlprogram.utils.data.get_samples
        dataset: "@/train_dataset"
        parser: "@/parser"
      token_threshold: "@/params.token_threshold"

model:
  type: torch.share_memory_
  model:
    type: torch.nn.Sequential
    modules:
      type: collections.OrderedDict
      items:
        - - "encoder"
          - type: mlprogram.nn.treegen.NLReader
            token_num: "@/encoder.word_encoder.vocab_size"
            char_num: "@/encoder.char_encoder.vocab_size"
            max_token_len: "@/params.max_word_length"
            char_embed_size: "@/params.char_embedding_size"
            hidden_size: "@/params.hidden_size"
            n_heads: "@/params.n_head"
            dropout: "@/params.dropout"
            n_blocks: "@/params.n_block"
        - - "decoder"
          - type: torch.nn.Sequential
            modules:
              type: collections.OrderedDict
              items:
                - - "action_sequence_reader"
                  - type: mlprogram.nn.treegen.ActionSequenceReader
                    rule_num: "@/encoder.action_sequence_encoder._rule_encoder.vocab_size"
                    token_num: "@/encoder.action_sequence_encoder._token_encoder.vocab_size"
                    node_type_num: "@/encoder.action_sequence_encoder._node_type_encoder.vocab_size"
                    max_arity: "@/params.max_arity"
                    rule_embed_size: "@/params.rule_embedding_size"
                    hidden_size: "@/params.hidden_size"
                    tree_conv_kernel_size: "@/params.tree_conv_kernel_size"
                    n_heads: "@/params.n_head"
                    dropout: "@/params.dropout"
                    n_blocks: "@/params.n_block"
                - - "decoder"
                  - type: mlprogram.nn.treegen.Decoder
                    rule_num: "@/encoder.action_sequence_encoder._rule_encoder.vocab_size"
                    max_depth: "@/params.max_tree_depth"
                    feature_size: "@/params.hidden_size"
                    hidden_size: "@/params/decoder_hidden_size"
                    out_size: "@/params.hidden_size"
                    n_heads: "@/params.n_head"
                    dropout: "@/params.dropout"
                    n_blocks: "@/params.n_block"
                - - "predictor"
                  - type: mlprogram.nn.action_sequence.Predictor
                    feature_size: "@/params.hidden_size"
                    reference_feature_size: "@/params.hidden_size"
                    rule_size: "@/encoder.action_sequence_encoder._rule_encoder.vocab_size"
                    token_size: "@/encoder.action_sequence_encoder._token_encoder.vocab_size"  # TODO
                    hidden_size: "@/params.hidden_size"

collate:
  type: mlprogram.utils.data.Collate
  device: "@/device"
  word_nl_query:
    type: mlprogram.utils.data.CollateOptions
    use_pad_sequence: true
    dim: 0
    padding_value: -1
  char_nl_query:
    type: mlprogram.utils.data.CollateOptions
    use_pad_sequence: true
    dim: 0
    padding_value: -1
  nl_query_features:
    type: mlprogram.utils.data.CollateOptions
    use_pad_sequence: true
    dim: 0
    padding_value: -1
  reference_features:
    type: mlprogram.utils.data.CollateOptions
    use_pad_sequence: true
    dim: 0
    padding_value: -1
  actions:
    type: mlprogram.utils.data.CollateOptions
    use_pad_sequence: true
    dim: 0
    padding_value: -1
  previous_actions:
    type: mlprogram.utils.data.CollateOptions
    use_pad_sequence: true
    dim: 0
    padding_value: -1
  previous_action_rules:
    type: mlprogram.utils.data.CollateOptions
    use_pad_sequence: true
    dim: 0
    padding_value: -1
  depthes:
    type: mlprogram.utils.data.CollateOptions
    use_pad_sequence: false
    dim: 1
    padding_value: 0
  adjacency_matrix:
    type: mlprogram.utils.data.CollateOptions
    use_pad_sequence: false
    dim: 0
    padding_value: 0
  action_queries:
    type: mlprogram.utils.data.CollateOptions
    use_pad_sequence: true
    dim: 0
    padding_value: -1
  ground_truth_actions:
    type: mlprogram.utils.data.CollateOptions
    use_pad_sequence: true
    dim: 0
    padding_value: -1

synthesizer:
  type: mlprogram.synthesizers.BeamSearch
  beam_size: "@/params.beam_size"
  max_step_size: "@/params.max_step_size"
  sampler:
    type: mlprogram.samplers.transform
    sampler:
      type: mlprogram.samplers.ActionSequenceSampler
      encoder: "@/encoder.action_sequence_encoder"
      is_subtype: "@/is_subtype"
      transform_input:
        type: mlprogram.functools.Compose
        funcs:
          type: collections.OrderedDict
          items:
            - - "extract_reference"
              - type: mlprogram.utils.transform.text.ExtractReference
                extract_reference: "@/extract_reference"
            - - "encode_word"
              - type: mlprogram.utils.transform.text.EncodeWordQuery
                word_encoder: "@/encoder.word_encoder"
            - - "encode_char"
              - type: mlprogram.utils.transform.text.EncodeCharacterQuery
                char_encoder: "@/encoder.char_encoder"
                max_word_length: "@/params.max_word_length"
      transform_action_sequence:
        type: mlprogram.functools.Compose
        funcs:
          type: collections.OrderedDict
          items:
            - - "add_previous_action"
              - type: mlprogram.utils.transform.action_sequence.AddPreviousActions
                action_sequence_encoder: "@/encoder.action_sequence_encoder"
                use_last: false
            - - "add_previous_action_rule"
              - type: mlprogram.utils.transform.action_sequence.AddPreviousActionRules
                action_sequence_encoder: "@/encoder.action_sequence_encoder"
                max_arity: "@/params.max_arity"
            - - "add_action_sequence_as_tree"
              - type: mlprogram.utils.transform.action_sequence.AddActionSequenceAsTree
                action_sequence_encoder: "@/encoder.action_sequence_encoder"
            - - "add_query"
              - type: mlprogram.utils.transform.action_sequence.AddQueryForTreeGenDecoder
                action_sequence_encoder: "@/encoder.action_sequence_encoder"
                max_depth: "@/params.max_tree_depth"
      collate: "@/collate"
      module: "@/model"
    transform: "@/parser.unparse"
