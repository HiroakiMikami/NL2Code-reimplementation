options:
    small:
        n_pretrain_iteration: 35000
        train_max_object: 3
        evaluate_max_object: 6
        size: 4
        resolution: 4
        n_evaluate_dataset: 30
        timeout_sec: 5
        interval_iter: 5000
    large:
        n_pretrain_iteration: 437500
        train_max_object: 13
        evaluate_max_object: 30
        size: 16
        resolution: 1
        n_evaluate_dataset: 30
        timeout_sec: 120
        interval_iter: 50000

device:
    type: torch.device
    type_str: "cuda"
    index: 0

to_action_sequence:
    type: mlprogram.utils.Sequence
    funcs:
        type: collections.OrderedDict
        items:
            - - "to_ast"
              - type: mlprogram.languages.csg.ToAst
            - - "to_sequence"
              - type: mlprogram.actions.AstToActionSequence

n_pixel:
    type: mul
    x: "@/option.size"
    y: "@/option.resolution"
n_feature_pixel:
    type: intdiv
    x: "@/n_pixel"
    y: 2

dataset:
    type: mlprogram.languages.csg.Dataset
    canvas_size: "@/option.size"
    min_object: 1
    max_object: "@/option.train_max_object"
    length_stride: 1
    degree_stride: 15
    reference: false

train_dataset:
    type: mlprogram.utils.data.transform
    dataset: "@/dataset"
    transform:
        type: mlprogram.utils.transform.EvaluateGroundTruth
        interpreter: "@/interpreter"
        reference: false
test_dataset:
    type: mlprogram.utils.data.transform
    dataset:
        type: mlprogram.utils.data.to_map_style_dataset
        dataset:
            type: mlprogram.languages.csg.Dataset
            canvas_size: "@/option.size"
            min_object: "@/option.train_max_object"
            max_object: "@/option.evaluate_max_object"
            length_stride: 1
            degree_stride: 15
            reference: false
            seed: 10000
        n: "@/option.n_evaluate_dataset"
    transform:
        type: mlprogram.utils.transform.EvaluateGroundTruth
        interpreter: "@/interpreter"
        reference: false
valid_dataset:
    type: mlprogram.utils.data.transform
    dataset:
        type: mlprogram.utils.data.to_map_style_dataset
        dataset:
            type: mlprogram.languages.csg.Dataset
            canvas_size: "@/option.size"
            min_object: "@/option.train_max_object"
            max_object: "@/option.evaluate_max_object"
            length_stride: 1
            degree_stride: 15
            reference: false
            seed: 20000
        n: "@/option.n_evaluate_dataset"
    transform:
        type: mlprogram.utils.transform.EvaluateGroundTruth
        interpreter: "@/interpreter"
        reference: false

interpreter:
    type: mlprogram.languages.csg.Interpreter
    width: "@/option.size"
    height: "@/option.size"
    resolution: "@/option.resolution"
model:
    type: torch.nn.Sequential
    modules:
        type: collections.OrderedDict
        items:
            - - "encoder"
              - type: mlprogram.nn.Apply
                in_keys:
                    - ["processed_input", "x"]
                out_key: "input_feature"
                module:
                    type: mlprogram.nn.CNN2d
                    in_channel: 1
                    out_channel: 16
                    hidden_channel: 32
                    n_conv_per_block: 2
                    n_block: 2
                    pool: 2
            - - "decoder"
              - type: torch.nn.Sequential
                modules:
                    type: collections.OrderedDict
                    items:
                        - - "action_sequence_reader"
                          - type: mlprogram.nn.action_sequence.ActionSequenceReader
                            n_rule: "@/encoder._rule_encoder.vocab_size"
                            n_token: "@/encoder._token_encoder.vocab_size"
                            hidden_size: 256
                        - - "decoder"
                          - type: mlprogram.nn.action_sequence.RnnDecoder
                            input_feature_size:
                                type: mul
                                x: 16
                                y:
                                    type: mul
                                    x: "@/n_feature_pixel"
                                    y: "@/n_feature_pixel"
                            action_feature_size: 256
                            output_feature_size: 512
                            dropout: 0.1
                        - - "predictor"
                          - type: mlprogram.nn.action_sequence.Predictor
                            feature_size: 512
                            reference_feature_size: 1
                            rule_size: "@/encoder._rule_encoder.vocab_size"
                            token_size: "@/encoder._token_encoder.vocab_size"
                            hidden_size: 512

collate:
    type: mlprogram.utils.data.Collate
    device: "@/device"
    processed_input:
        type: mlprogram.utils.data.CollateOptions
        use_pad_sequence: false
        dim: 0
        padding_value: 0
    input_feature:
        type: mlprogram.utils.data.CollateOptions
        use_pad_sequence: false
        dim: 0
        padding_value: 0
    reference_features:
        type: mlprogram.utils.data.CollateOptions
        use_pad_sequence: true
        dim: 0
        padding_value: 0
    previous_actions:
        type: mlprogram.utils.data.CollateOptions
        use_pad_sequence: true
        dim: 0
        padding_value: -1
    hidden_state:
        type: mlprogram.utils.data.CollateOptions
        use_pad_sequence: false
        dim: 0
        padding_value: 0
    state:
        type: mlprogram.utils.data.CollateOptions
        use_pad_sequence: false
        dim: 0
        padding_value: 0
    ground_truth_actions:
        type: mlprogram.utils.data.CollateOptions
        use_pad_sequence: true
        dim: 0
        padding_value: -1

sampler:
    type: mlprogram.samplers.transform
    sampler:
        type: mlprogram.samplers.ActionSequenceSampler
        encoder: "@/encoder"
        get_token_type:
            type: mlprogram.languages.csg.GetTokenType
        is_subtype:
            type: mlprogram.languages.csg.IsSubtype
        transform_input:
            type: mlprogram.utils.Compose
            funcs:
                type: collections.OrderedDict
                items:
                    - - "add_reference"
                      - type: mlprogram.utils.transform.action_sequence.AddEmptyReference
                    - - "transform_canvas"
                      - type: mlprogram.utils.transform.csg.TransformCanvas
                        targets: ["input"]
        transform_action_sequence:
            type: mlprogram.utils.transform.action_sequence.TransformActionSequenceForRnnDecoder
            action_sequence_encoder: "@/encoder"
            train: false
        collate: "@/collate"
        module: "@/model"
    transform:
        type: mlprogram.languages.csg.ToCsgAst
synthesizer:
  type: mlprogram.synthesizers.FilteredSynthesizer
  synthesizer:
    type: mlprogram.synthesizers.SynthesizerWithTimeout
    synthesizer:
      type: mlprogram.synthesizers.SMC
      max_step_size:
        type: mul
        x: 5 # up to 5 actions are required to create an AST node
        y: 
          type: mul
          x: 5 # up to (3~5)*max_object nodes are requried to create AST
          y: "@/option.evaluate_max_object"
      initial_particle_size: 100
      max_try_num: 50
      sampler: "@/sampler"
      to_key:
          type: mlprogram.utils.Pick
          key: "action_sequence"
    timeout_sec: "@/option.timeout_sec"
  score:
    type: mlprogram.metrics.TestCaseResult
    interpreter: "@/interpreter"
    reference: false
    use_input: True
    metric:
      type: mlprogram.metrics.Iou
  threshold: 0.9

transform:
    type: mlprogram.utils.Sequence
    funcs:
        type: collections.OrderedDict
        items:
            - - "choice"
              - type: mlprogram.utils.transform.RandomChoice
            - - "add_reference"
              - type: mlprogram.utils.transform.action_sequence.AddEmptyReference
            - - "transform_canvas"
              - type: mlprogram.utils.transform.csg.TransformCanvas
                targets: ["input"]
            - - "transform_code"
              - type: mlprogram.utils.transform.action_sequence.TransformCode
                to_action_sequence: "@/to_action_sequence"
            - - "transform_action_sequence"
              - type: mlprogram.utils.transform.action_sequence.TransformActionSequenceForRnnDecoder
                action_sequence_encoder: "@/encoder"
                train: true
            - - "transform_ground_truth"
              - type: mlprogram.utils.transform.action_sequence.TransformGroundTruth
                action_sequence_encoder: "@/encoder"
