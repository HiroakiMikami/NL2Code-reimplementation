options:
    small:
        n_pretrain_iteration: 5000
        n_train_iteration: 15000
        train_max_object: 3
        evaluate_max_object: 6
        size: 4
        resolution: 4
        n_evaluate_dataset: 30
        timeout_sec: 5
        interval_iter: 3000
    large:
        n_pretrain_iteration: 156250
        n_train_iteration: 281250
        train_max_object: 13
        evaluate_max_object: 30
        size: 16
        resolution: 1
        n_evaluate_dataset: 30
        timeout_sec: 120
        interval_iter: 50000

device:
    type: torch.device
    type_str: "cuda"
    index: 0

parser:
    type: mlprogram.languages.csg.Parser

n_pixel:
    type: mul
    x: "@/option.size"
    y: "@/option.resolution"
n_feature_pixel:
    type: intdiv
    lhs: "@/n_pixel"
    rhs: 2

dataset:
    type: mlprogram.languages.csg.Dataset
    canvas_size: "@/option.size"
    min_object: 1
    max_object: "@/option.train_max_object"
    length_stride: 1
    degree_stride: 15
    reference: true

encoder:
  type: with_file_cache
  path:
    type: os.path.join
    args:
      - "@/output_dir"
      - "encoder.pt"
  config:
    type: mlprogram.encoders.ActionSequenceEncoder
    samples:
        type: mlprogram.languages.csg.get_samples
        dataset: "@/dataset"
        parser: "@/parser"
    token_threshold: 0

train_dataset:
    type: mlprogram.utils.data.transform
    dataset: "@/dataset"
    transform:
        type: mlprogram.languages.csg.transform.AddTestCases
        interpreter: "@/interpreter"
test_dataset:
    type: mlprogram.utils.data.transform
    dataset:
        type: mlprogram.utils.data.to_map_style_dataset
        dataset:
            type: mlprogram.languages.csg.Dataset
            canvas_size: "@/option.size"
            min_object: "@/option.train_max_object"
            max_object: "@/option.evaluate_max_object"
            length_stride: 1
            degree_stride: 15
            reference: true
            seed: 10000
        n: "@/option.n_evaluate_dataset"
    transform:
        type: mlprogram.languages.csg.transform.AddTestCases
        interpreter: "@/interpreter"
valid_dataset:
    type: mlprogram.utils.data.transform
    dataset:
        type: mlprogram.utils.data.to_map_style_dataset
        dataset:
            type: mlprogram.languages.csg.Dataset
            canvas_size: "@/option.size"
            min_object: "@/option.train_max_object"
            max_object: "@/option.evaluate_max_object"
            length_stride: 1
            degree_stride: 15
            reference: true
            seed: 20000
        n: "@/option.n_evaluate_dataset"
    transform:
        type: mlprogram.languages.csg.transform.AddTestCases
        interpreter: "@/interpreter"

interpreter:
    type: mlprogram.languages.csg.Interpreter
    width: "@/option.size"
    height: "@/option.size"
    resolution: "@/option.resolution"
    delete_used_reference: true
model:
    type: torch.share_memory_
    model:
        type: torch.nn.Sequential
        modules:
            type: collections.OrderedDict
            items:
                - - "encode_input"
                  - type: mlprogram.nn.Apply
                    in_keys:
                        - ["state@test_case_tensor", "x"]
                    out_key: "state@test_case_feature"
                    module:
                        type: mlprogram.nn.CNN2d
                        in_channel: 1
                        out_channel: 16
                        hidden_channel: 32
                        n_conv_per_block: 2
                        n_block: 2
                        pool: 2
                - - "encoder"
                  - type: mlprogram.nn.pbe_with_repl.Encoder
                    module:
                        type: mlprogram.nn.CNN2d
                        in_channel: 2
                        out_channel: 16
                        hidden_channel: 32
                        n_conv_per_block: 2
                        n_block: 2
                        pool: 2
                - - "decoder"
                  - type: torch.nn.Sequential
                    modules:
                        type: collections.OrderedDict
                        items:
                            - - "action_sequence_reader"
                              - type: mlprogram.nn.action_sequence.ActionSequenceReader
                                n_rule: "@/encoder._rule_encoder.vocab_size"
                                n_token: "@/encoder._token_encoder.vocab_size"
                                hidden_size: 256
                            - - "decoder"
                              - type: mlprogram.nn.action_sequence.RnnDecoder
                                input_feature_size:
                                    type: mul
                                    x: 32  # 2 * 16
                                    y:
                                        type: mul
                                        x: "@/n_feature_pixel"
                                        y: "@/n_feature_pixel"
                                action_feature_size: 256
                                output_feature_size: 512
                                dropout: 0.1
                            - - "predictor"
                              - type: mlprogram.nn.action_sequence.Predictor
                                feature_size: 512
                                reference_feature_size:
                                    type: mul
                                    x: 16  # 16
                                    y:
                                        type: mul
                                        x: "@/n_feature_pixel"
                                        y: "@/n_feature_pixel"
                                rule_size: "@/encoder._rule_encoder.vocab_size"
                                token_size: "@/encoder._token_encoder.vocab_size"
                                hidden_size: 512
                - - "value"
                  - type: mlprogram.nn.Apply
                    in_keys:
                        - ["state@input_feature", "x"]
                    out_key: "state@value"
                    module:
                        type: mlprogram.nn.MLP
                        in_channel:
                            type: mul
                            x: 2
                            y:
                                type: mul
                                x: 16  # 16
                                y:
                                    type: mul
                                    x: "@/n_feature_pixel"
                                    y: "@/n_feature_pixel"
                        out_channel: 1
                        hidden_channel: 512
                        n_linear: 2
                        activation:
                            type: torch.nn.Sigmoid
                    value_type: "tensor"

collate:
    type: mlprogram.utils.data.Collate
    device: "@/device"
    test_case_tensor:
        type: mlprogram.utils.data.CollateOptions
        use_pad_sequence: false
        dim: 0
        padding_value: 0
    test_case_feature:
        type: mlprogram.utils.data.CollateOptions
        use_pad_sequence: false
        dim: 0
        padding_value: 0
    input_feature:
        type: mlprogram.utils.data.CollateOptions
        use_pad_sequence: false
        dim: 0
        padding_value: 0
    reference_features:
        type: mlprogram.utils.data.CollateOptions
        use_pad_sequence: true
        dim: 0
        padding_value: 0
    variables_tensor:
        type: mlprogram.utils.data.CollateOptions
        use_pad_sequence: true
        dim: 0
        padding_value: 0
    previous_actions:
        type: mlprogram.utils.data.CollateOptions
        use_pad_sequence: true
        dim: 0
        padding_value: -1
    hidden_state:
        type: mlprogram.utils.data.CollateOptions
        use_pad_sequence: false
        dim: 0
        padding_value: 0
    state:
        type: mlprogram.utils.data.CollateOptions
        use_pad_sequence: false
        dim: 0
        padding_value: 0
    ground_truth_actions:
        type: mlprogram.utils.data.CollateOptions
        use_pad_sequence: true
        dim: 0
        padding_value: -1
    reward:
        type: mlprogram.utils.data.CollateOptions
        use_pad_sequence: false
        dim: 0
        padding_value: 0

transform_input:
    type: mlprogram.functools.Sequence
    funcs:
        type: collections.OrderedDict
        items:
            - - "transform_canvas"
              - type: mlprogram.languages.csg.transform.TransformCanvas
transform_action_sequence:
    type: mlprogram.functools.Sequence
    funcs:
        type: collections.OrderedDict
        items:
            - - "add_previous_actions"
              - type: mlprogram.utils.transform.action_sequence.AddPreviousActions
                action_sequence_encoder: "@/encoder"
                n_dependent: 1
            - - "add_state"
              - type: mlprogram.utils.transform.action_sequence.AddStateForRnnDecoder
transform:
    type: mlprogram.functools.Sequence
    funcs:
        type: collections.OrderedDict
        items:
            - - "transform_input"
              - "@/transform_input"
            - - "transform_code"
              - type: mlprogram.utils.transform.action_sequence.GroundTruthToActionSequence
                parser: "@/parser"
            - - "transform_action_sequence"
              - "@/transform_action_sequence"
            - - "transform_ground_truth"
              - type: mlprogram.utils.transform.action_sequence.EncodeActionSequence
                action_sequence_encoder: "@/encoder"

subsampler:
    type: mlprogram.samplers.transform
    sampler:
        type: mlprogram.samplers.ActionSequenceSampler
        encoder: "@/encoder"
        is_subtype:
            type: mlprogram.languages.csg.IsSubtype
        transform_input: "@/transform_input"
        transform_action_sequence: "@/transform_action_sequence"
        collate: "@/collate"
        module: "@/model"
    transform: "@/parser.unparse"
subsynthesizer:
    type: mlprogram.synthesizers.SMC
    max_step_size: 5
    max_try_num: 1
    initial_particle_size: 1
    sampler: "@/subsampler"
    to_key:
        type: Pick
        key: "state@action_sequence"
sampler:
    type: mlprogram.samplers.SequentialProgramSampler
    synthesizer: "@/subsynthesizer"
    transform_input:
        type: mlprogram.languages.csg.transform.TransformCanvas
    collate: "@/collate"
    encoder: "@/model.encode_input"
    interpreter: "@/interpreter"
    expander:
        type: "mlprogram.languages.csg.Expander"
train_synthesizer:
    type: mlprogram.synthesizers.SMC
    max_step_size:
        type: mul
        x: "@/option.train_max_object"
        y: 3
    initial_particle_size: 1
    max_try_num: 1
    sampler:
        type: mlprogram.samplers.FilteredSampler
        sampler: "@/sampler"
        score:
            type: mlprogram.metrics.TestCaseResult
            interpreter: "@/interpreter"
            metric:
                type: mlprogram.metrics.Iou
        threshold: 0.9
    to_key:
        type: Pick
        key: "state@interpreter_state"
evaluate_synthesizer:
    type: mlprogram.synthesizers.SynthesizerWithTimeout
    synthesizer:
        type: mlprogram.synthesizers.SMC
        max_step_size:
            type: mul
            x: "@/option.evaluate_max_object"
            y: 5
        initial_particle_size: 100
        sampler:
            type: mlprogram.samplers.SamplerWithValueNetwork
            sampler: "@/sampler"
            transform:
                type: mlprogram.functools.Compose
                funcs:
                    type: collections.OrderedDict
                    items:
                        - - "transform_canvas"
                          - type: mlprogram.languages.csg.transform.TransformCanvas
            collate: "@/collate"
            value_network:
                type: torch.nn.Sequential
                modules:
                    type: collections.OrderedDict
                    items:
                        - - "encoder"
                          - "@/model.encoder"
                        - - "value"
                          - "@/model.value"
                        - - "pick"
                          - type: mlprogram.nn.Function
                            f: 
                                type: Pick
                                key: "state@value"
            batch_size: 1
        to_key:
            type: Pick
            key: "state@interpreter_state"
    timeout_sec: "@/option.timeout_sec"

to_episode:
    type: mlprogram.utils.transform.pbe.ToEpisode
    interpreter: "@/interpreter"
    expander:
        type: mlprogram.languages.csg.Expander
