{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NL2Code django train",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yje9hqtcUQ_f"
      },
      "source": [
        "### Initialization\n",
        "* Check whether the runtime is host or local.\n",
        "* Mount Google Drive when using the host runtime."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "FwqGy_GyUQnw"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/gdrive')\n",
        "  runtime = \"host\"\n",
        "except:\n",
        "  runtime = \"local\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_S457sT6QMUr"
      },
      "source": [
        "### Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "2LYvG4iCQUwh"
      },
      "outputs": [],
      "source": [
        "#@title Parameters\n",
        "#@markdown |Name            |Description|\n",
        "#@markdown |:---            |:---|\n",
        "#@markdown |`seed`|The random seed|\n",
        "seed = 20367 #@param {type: \"number\"}\n",
        "\n",
        "#@markdown ### `nl2code` Repositories\n",
        "#@markdown |Name            |Description|\n",
        "#@markdown |:---            |:---|\n",
        "#@markdown |`repository_url`|The URL of `nl2code` git repository (enabled only in the host runtime)|\n",
        "#@markdown |`branch_name`   |The branch name (enabled only in the host runtime)|\n",
        "repository_url = \"https://github.com/HiroakiMikami/NL2Code-reimplementation\" #@param {type: \"string\"}\n",
        "branch_name = \"master\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown ### Dataset Settings\n",
        "#@markdown |Name               |Description|\n",
        "#@markdown |:---               |:---|\n",
        "#@markdown |`max_action_length`|The maximum action length|\n",
        "#@markdown |`word_threshold`   ||\n",
        "#@markdwon |`token_threshold`  ||\n",
        "max_action_length = 100 #@param {type: \"number\"}\n",
        "word_threshold = 5 #@param {type: \"number\"}\n",
        "token_threshold = 5 #@param {type: \"number\"}\n",
        "\n",
        "#@markdown ### Model Parameters\n",
        "#@markdown |Name                     |Description|\n",
        "#@markdown |:---                     |:---|\n",
        "#@markdown |`embedding_dim`          |The dimension of word, token, and rule embeddings|\n",
        "#@markdown |`node_type_embedding_dim`|The dimension of node type embedding dim|\n",
        "#@markdown |`lstm_state_size`        |The size of LSTM state|\n",
        "#@markdwon |`hidden_state_size`      |The size of attention hidden state|\n",
        "embedding_dim = 128 #@param {type: \"number\"}\n",
        "node_type_embedding_dim = 64 #@param {type: \"number\"}\n",
        "lstm_state_size = 256 #@param {type: \"number\"}\n",
        "hidden_state_size = 50 #@param {type: \"number\"}\n",
        "\n",
        "#@markdown ### Training Settings\n",
        "#@markdown |Name                |Description|\n",
        "#@markdown |:---                |:---|\n",
        "#@markdown |`batch_size`        |The minibatch size|\n",
        "#@markdown |`dropout`           |The probability of dropout|\n",
        "#@markdown |`num_epochs`        |The numer of epoch|\n",
        "#@markdown |`num_train`         |The number of entries used for training|\n",
        "batch_size = 10 #@param {type: \"number\"}\n",
        "dropout = 0.2 #@param {type: \"number\"}\n",
        "num_epochs = 50 #@param {type: \"number\"}\n",
        "num_train = 0 #@param {type: \"number\"}\n",
        "\n",
        "\n",
        "#@markdown ### Evaluation Settings\n",
        "#@markdown |Name                 |Description|\n",
        "#@markdown |:---                 |:---|\n",
        "#@markdown |`beam_size`          |The beam size|\n",
        "#@markdown |`evaluation_interval`|The number of epochs between two evaluation|\n",
        "#@markdown |`evaluation_metrics` |The metrics used for evaluation|\n",
        "beam_size = 15 #@param {type: \"number\"}\n",
        "evaluation_interval = 5 #@param {type: \"number\"}\n",
        "evaluation_metrics = \"bleu4\" #@param [\"bleu4\", \"accuracy\"]\n",
        "\n",
        "#@markdown ### Other Settings\n",
        "#@markdown |Name    |Description|\n",
        "#@markdown |:---    |:---|\n",
        "#@markdown |`device`|The id of GPU. `-1` means that CPU is used.|\n",
        "device = 0 #@param {type: \"number\"}\n",
        "\n",
        "#@markdown ### Filepathes\n",
        "#@markdown |Name             |Description|\n",
        "#@markdown |:---             |:---|\n",
        "#@markdown |`dataset_path`   |The path of the dataset.|\n",
        "#@markdown |`output_dir_path`|The directory of the directory that will contain the training results.|\n",
        "dataset_path = \"/gdrive/My Drive/NL2Code/django/dataset.pickle\" #@param {type: \"string\"}\n",
        "output_dir_path = \"/gdrive/My Drive/NL2Code/django/result/\" #@param {type: \"string\"}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_BembldCdOO1"
      },
      "source": [
        "### Setup\n",
        "* Download the codebase (when using the host runtime)\n",
        "  1. Clone git repository and move to the specified branch\n",
        "  2. Install modules\n",
        "* Use GPU\n",
        "* Fix the random seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "FIZJmuz8QFn_"
      },
      "outputs": [],
      "source": [
        "if runtime == \"host\":\n",
        "    %cd /content\n",
        "    !rm -rf NL2Code\n",
        "    ![ ! -e NL2Code ] && git clone $repository_url NL2Code\n",
        "    %cd NL2Code\n",
        "    !git checkout $branch_name\n",
        "    !git checkout origin/feature/pytorch\n",
        "    !pip install -e .\n",
        "    !pip install -e . \".[examples]\"\n",
        "# load tqdm\n",
        "!pip install --force https://github.com/chengs/tqdm/archive/colab.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Rsyz7B0Ukxa7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "if device != -1:\n",
        "    torch.cuda.set_device(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "GwjlAkY1fR5j"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "\n",
        "SEED_MAX = 2**32 - 1\n",
        "\n",
        "root_rng = np.random.RandomState(seed)\n",
        "random.seed(root_rng.randint(SEED_MAX))\n",
        "np.random.seed(root_rng.randint(SEED_MAX))\n",
        "torch.manual_seed(root_rng.randint(SEED_MAX))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Oz7sdzxUi70b"
      },
      "source": [
        "### Setup training\n",
        "* Load the dataset\n",
        "* Split the dataset into train, test, valid\n",
        "* Create and save encoder\n",
        "* Prepare dataset\n",
        "* Create model\n",
        "* Create optimizer\n",
        "* Use GPU (if needed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "h7kdglcUjDTQ"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "from nl2code_examples.django import RawDataset\n",
        "with open(dataset_path, \"rb\") as f:\n",
        "    dataset = pickle.load(f)\n",
        "dataset = RawDataset(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "IrFgwHCntjkt"
      },
      "outputs": [],
      "source": [
        "from nl2code_examples.django import RawDataset, Entry\n",
        "train_raw_dataset = RawDataset(dataset[\"train\"])\n",
        "test_raw_dataset = RawDataset(dataset[\"test\"])\n",
        "val_raw_dataset = RawDataset(dataset[\"valid\"])\n",
        "if num_train != 0:\n",
        "    train_raw_dataset = RawDataset(list(train)[:num_train])\n",
        "    test_raw_dataset = RawDataset(list(train)[:num_train])\n",
        "    val_raw_dataset = RawDataset(list(train)[:num_train])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "V0WsjTbjHOQ_"
      },
      "outputs": [],
      "source": [
        "from nl2code_examples.django import DatasetEncoder\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "!mkdir -p \"$output_dir_path\"\n",
        "encoder = DatasetEncoder(train_raw_dataset.samples, word_threshold, token_threshold)\n",
        "with open(os.path.join(output_dir_path, \"encoder.pickle\"), \"wb\") as file:\n",
        "    pickle.dump(encoder, file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "11mMmXAuutb9"
      },
      "outputs": [],
      "source": [
        "from nl2code_examples.django import RawDataset, TrainDataset, EvalDataset\n",
        "train_dataset = TrainDataset(train_raw_dataset, encoder)\n",
        "test_dataset = EvalDataset(test_raw_dataset, encoder, max_action_length, skip_impossible_entry=False)\n",
        "valid_dataset = EvalDataset(val_raw_dataset, encoder, max_action_length, skip_impossible_entry=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "QcAaeUZMtqSt"
      },
      "outputs": [],
      "source": [
        "from nl2code_examples.django import TrainingModel\n",
        "model = TrainingModel(encoder, embedding_dim, node_type_embedding_dim,\n",
        "                      lstm_state_size, hidden_state_size,\n",
        "                      dropout)\n",
        "if device != -1:\n",
        "    model = model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ho3IgH4e04pi"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "optimizer = optim.Adam(model.parameters())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sJw73TjO1CNc"
      },
      "source": [
        "### Training Loop\n",
        "* Launch TensorBoard\n",
        "* Run training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "IPJ_QTj3Lfp2"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "tensorboard_path = \"tensorboard\"\n",
        "if runtime == \"host\":\n",
        "    %tensorboard --logdir $tensorboard_path\n",
        "else:\n",
        "    !pkill tensorboard.\n",
        "    import subprocess\n",
        "    import os\n",
        "    subprocess.Popen([\"tensorboard\", \"--logdir\", tensorboard_path])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "jAPAqZYz3A2p"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm_notebook as tqdm\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.utils.rnn as rnn\n",
        "from typing import List\n",
        "from nl2code_examples.django import TrainDataset, validate\n",
        "from nl2prog.nn import Loss, Accuracy\n",
        "import nl2code.nn.utils.rnn as nrnn\n",
        "from nl2prog.language.python import is_subtype\n",
        "from nl2prog.utils.nl2code import BeamSearchSynthesizer\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "def query_embedding(query: List[str]):\n",
        "    x = encoder.annotation_encoder.batch_encode(query)\n",
        "    if device != -1:\n",
        "        x = x.cuda()\n",
        "    embedding =  model.encoder(nrnn.pad_sequence([x]))\n",
        "    embedding = embedding.data\n",
        "    return embedding.view(len(query), -1)\n",
        "\n",
        "synthesizer = BeamSearchSynthesizer(beam_size, model.predictor,\n",
        "                                    encoder.action_sequence_encoder, is_subtype,\n",
        "                                    max_steps=max_action_length)\n",
        "writer = SummaryWriter(tensorboard_path)\n",
        "\n",
        "loss_function = Loss()\n",
        "acc_function = Accuracy()\n",
        "best_score = -1\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "    loader = DataLoader(train_dataset, batch_size=batch_size,\n",
        "                        shuffle=True,\n",
        "                        num_workers=4,\n",
        "                        collate_fn=TrainDataset.collate)\n",
        "    avg_loss = 0.0\n",
        "    model.train()\n",
        "    for i, (query, action, prev_action) in enumerate(loader):\n",
        "        query = rnn.pack_sequence(query, enforce_sorted=False)\n",
        "        action = rnn.pack_sequence(action, enforce_sorted=False)\n",
        "        prev_action_train = [x[:-1] for x in prev_action]\n",
        "        action_ground_truth = [x[1:] for x in prev_action]\n",
        "        prev_action_train = rnn.pack_sequence(prev_action_train, enforce_sorted=False)\n",
        "        action_ground_truth = rnn.pack_sequence(action_ground_truth, enforce_sorted=False)\n",
        "        if device != -1:\n",
        "            query = query.cuda()\n",
        "            action = action.cuda()\n",
        "            prev_action_train = prev_action_train.cuda()\n",
        "            action_ground_truth = action_ground_truth.cuda()\n",
        "        query = nrnn.pad_packed_sequence(query, padding_value=-1)\n",
        "        action = nrnn.pad_packed_sequence(action, padding_value=-1)\n",
        "        prev_action_train = nrnn.pad_packed_sequence(prev_action_train, padding_value=-1)\n",
        "        action_ground_truth = nrnn.pad_packed_sequence(action_ground_truth, padding_value=-1)\n",
        "\n",
        "        rule_prob, token_prob, copy_prob, _, _ = model(query, action, prev_action_train)\n",
        "        loss = loss_function(rule_prob, token_prob, copy_prob, action_ground_truth)\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        step = epoch * len(train_dataset) + i * batch_size\n",
        "        l = loss.cpu().detach().numpy()\n",
        "        avg_loss += l / len(loader)\n",
        "        writer.add_scalars('training', { \"loss\": l }, step)\n",
        "    print(epoch, avg_loss)\n",
        "\n",
        "    # Evaluate test dataset\n",
        "    if (epoch + 1) % evaluation_interval == 0:\n",
        "        model.eval()\n",
        "        accuracy = 0\n",
        "        bleu4 = 0\n",
        "        for query, query_with_placeholder, ground_truth in tqdm(test_dataset):\n",
        "            result = validate(query, query_with_placeholder, ground_truth, query_embedding, synthesizer)\n",
        "            accuracy += 1 if result.is_match else 0\n",
        "            bleu4 += result.bleu4\n",
        "        accuracy /= len(test_dataset)\n",
        "        bleu4 /= len(test_dataset)\n",
        "        writer.add_scalars('test', { \"accuracy\": accuracy, \"bleu4\": bleu4 }, epoch)\n",
        "        print(epoch, bleu4, accuracy)\n",
        "        score = bleu4\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            torch.save(model.state_dict(), os.path.join(output_dir_path, \"best_model.pickle\"))\n",
        "\n",
        "if best_score < 0:\n",
        "    torch.save(model.state_dict(), os.path.join(output_dir_path, \"best_model.pickle\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "toeP4RGEeK1b"
      },
      "source": [
        "### Run Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "BAjEaEWYeKGF"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm_notebook as tqdm\n",
        "import os\n",
        "import pickle\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.utils.rnn as rnn\n",
        "from typing import List\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from nl2prog.nn import Loss\n",
        "import nl2code.nn.utils.rnn as nrnn\n",
        "from nl2prog.language.python import is_subtype\n",
        "from nl2prog.utils.nl2code import BeamSearchSynthesizer\n",
        "from nl2code_examples.django import validate, unparse\n",
        "\n",
        "def query_embedding(query: List[str]):\n",
        "    x = encoder.annotation_encoder.batch_encode(query)\n",
        "    if device != -1:\n",
        "        x = x.cuda()\n",
        "    embedding =  model.encoder(nrnn.pad_sequence([x]))\n",
        "    embedding = embedding.data\n",
        "    return embedding.view(len(query), -1)\n",
        "\n",
        "synthesizer = BeamSearchSynthesizer(beam_size, model.predictor,\n",
        "                                    encoder.action_sequence_encoder, is_subtype,\n",
        "                                    max_steps=max_action_length)\n",
        "\n",
        "\n",
        "# Validate the model\n",
        "model.load_state_dict(torch.load(os.path.join(output_dir_path, \"best_model.pickle\")))\n",
        "accuracy = 0\n",
        "bleu4 = 0\n",
        "model.eval()\n",
        "results = []\n",
        "for query, query_with_placeholder, ground_truth in tqdm(valid_dataset):\n",
        "    result = validate(query, query_with_placeholder, ground_truth, query_embedding, synthesizer)\n",
        "    accuracy += 1 if result.is_match else 0\n",
        "    bleu4 += result.bleu4\n",
        "    results.append(result)\n",
        "accuracy /= len(valid_dataset)\n",
        "bleu4 /= len(valid_dataset)\n",
        "with open(os.path.join(output_dir_path, \"validation_results.pickle\"), \"wb\") as file:\n",
        "    pickle.dump(results, file)\n",
        "print(accuracy, bleu4)\n",
        "writer.add_scalars('validation', { \"accuracy\": accuracy, \"bleu4\": bleu4 })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cYIEAmUEq1PI"
      },
      "source": [
        "### Post-Process\n",
        "\n",
        "* Save tensorboard output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "-iB3slMVq0eK"
      },
      "outputs": [],
      "source": [
        "!zip -r \"$output_dir_path/tensorboard.zip\" $tensorboard_path"
      ]
    }
  ]
}