{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NL2Code django train",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yje9hqtcUQ_f",
        "colab_type": "text"
      },
      "source": [
        "### Initialization\n",
        "* Check whether the runtime is host or local.\n",
        "* Mount Google Drive when using the host runtime."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwqGy_GyUQnw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  from google.colab import auth\n",
        "  auth.authenticate_user()\n",
        "  from google.colab import drive\n",
        "  drive.mount('/gdrive')\n",
        "  runtime = \"host\"\n",
        "except:\n",
        "  runtime = \"local\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_S457sT6QMUr",
        "colab_type": "text"
      },
      "source": [
        "### Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LYvG4iCQUwh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Parameters\n",
        "#@markdown |Name            |Description|\n",
        "#@markdown |:---            |:---|\n",
        "#@markdown |`seed`|The random seed|\n",
        "seed = 20367 #@param {type: \"number\"}\n",
        "\n",
        "#@markdown ### `nl2code` Repositories\n",
        "#@markdown |Name            |Description|\n",
        "#@markdown |:---            |:---|\n",
        "#@markdown |`repository_url`|The URL of `nl2code` git repository (enabled only in the host runtime)|\n",
        "#@markdown |`branch_name`   |The branch name (enabled only in the host runtime)|\n",
        "repository_url = \"https://github.com/HiroakiMikami/NL2Code-reimplementation\" #@param {type: \"string\"}\n",
        "branch_name = \"master\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown ### Dataset Settings\n",
        "#@markdown |Name               |Description|\n",
        "#@markdown |:---               |:---|\n",
        "#@markdown |`max_action_length`|The maximum action length|\n",
        "#@markdown |`word_threshold`   ||\n",
        "#@markdwon |`token_threshold`  ||\n",
        "max_action_length = 100 #@param {type: \"number\"}\n",
        "word_threshold = 5 #@param {type: \"number\"}\n",
        "token_threshold = 5 #@param {type: \"number\"}\n",
        "\n",
        "#@markdown ### Model Parameters\n",
        "#@markdown |Name                     |Description|\n",
        "#@markdown |:---                     |:---|\n",
        "#@markdown |`embedding_dim`          |The dimension of word, token, and rule embeddings|\n",
        "#@markdown |`node_type_embedding_dim`|The dimension of node type embedding dim|\n",
        "#@markdown |`lstm_state_size`        |The size of LSTM state|\n",
        "#@markdwon |`hidden_state_size`      |The size of attention hidden state|\n",
        "embedding_dim = 128 #@param {type: \"number\"}\n",
        "node_type_embedding_dim = 64 #@param {type: \"number\"}\n",
        "lstm_state_size = 256 #@param {type: \"number\"}\n",
        "hidden_state_size = 50 #@param {type: \"number\"}\n",
        "\n",
        "#@markdown ### Training Settings\n",
        "#@markdown |Name                |Description|\n",
        "#@markdown |:---                |:---|\n",
        "#@markdown |`batch_size`        |The minibatch size|\n",
        "#@markdown |`dropout`           |The probability of dropout|\n",
        "#@markdown |`num_epochs`        |The numer of epoch|\n",
        "#@markdown |`num_train`         |The number of entries used for training|\n",
        "batch_size = 10 #@param {type: \"number\"}\n",
        "dropout = 0.2 #@param {type: \"number\"}\n",
        "num_epochs = 50 #@param {type: \"number\"}\n",
        "num_train = 0 #@param {type: \"number\"}\n",
        "\n",
        "\n",
        "#@markdown ### Evaluation Settings\n",
        "#@markdown |Name                 |Description|\n",
        "#@markdown |:---                 |:---|\n",
        "#@markdown |`beam_size`          |The beam size|\n",
        "#@markdown |`evaluation_interval`|The number of epochs between two evaluation|\n",
        "#@markdown |`evaluation_metrics` |The metrics used for evaluation|\n",
        "beam_size = 15 #@param {type: \"number\"}\n",
        "evaluation_interval = 5 #@param {type: \"number\"}\n",
        "evaluation_metrics = \"bleu4\" #@param [\"bleu4\", \"accuracy\"]\n",
        "\n",
        "#@markdown ### Other Settings\n",
        "#@markdown |Name    |Description|\n",
        "#@markdown |:---    |:---|\n",
        "#@markdown |`device`|The id of GPU. `-1` means that CPU is used.|\n",
        "device = 0 #@param {type: \"number\"}\n",
        "\n",
        "#@markdown ### Filepathes\n",
        "#@markdown |Name             |Description|\n",
        "#@markdown |:---             |:---|\n",
        "#@markdown |`dataset_path`   |The path of the dataset.|\n",
        "#@markdown |`output_dir_path`|The directory of the directory that will contain the training results.|\n",
        "dataset_path = \"/gdrive/My Drive/NL2Code/django/dataset.pickle\" #@param {type: \"string\"}\n",
        "output_dir_path = \"/gdrive/My Drive/NL2Code/django/result/\" #@param {type: \"string\"}\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BembldCdOO1",
        "colab_type": "text"
      },
      "source": [
        "### Setup\n",
        "* Download the codebase (when using the host runtime)\n",
        "  1. Clone git repository and move to the specified branch\n",
        "  2. Install modules\n",
        "* Use GPU\n",
        "* Fix the random seed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIZJmuz8QFn_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if runtime == \"host\":\n",
        "    %cd /content\n",
        "    !rm -rf NL2Code\n",
        "    #![ ! -e NL2Code ] && git clone $repository_url NL2Code\n",
        "    !gcloud source repos clone NL2Code-reimplementation --project development-environment-192405\n",
        "    !mv NL2Code-reimplementation NL2Code\n",
        "    %cd NL2Code\n",
        "    #!git checkout $branch_name\n",
        "    !git checkout origin/feature/pytorch\n",
        "    !pip install -e .\n",
        "    !pip install -e . \".[examples]\"\n",
        "# load tqdm\n",
        "!pip install --force https://github.com/chengs/tqdm/archive/colab.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rsyz7B0Ukxa7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "if device != -1:\n",
        "    torch.cuda.set_device(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwjlAkY1fR5j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "\n",
        "SEED_MAX = 2**32 - 1\n",
        "\n",
        "root_rng = np.random.RandomState(seed)\n",
        "random.seed(root_rng.randint(SEED_MAX))\n",
        "np.random.seed(root_rng.randint(SEED_MAX))\n",
        "torch.manual_seed(root_rng.randint(SEED_MAX))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oz7sdzxUi70b",
        "colab_type": "text"
      },
      "source": [
        "### Setup training\n",
        "* Load the dataset\n",
        "* Split the dataset into train, test, valid\n",
        "* Create and save encoder\n",
        "* Prepare dataset\n",
        "* Create model\n",
        "* Create optimizer\n",
        "* Use GPU (if needed)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7kdglcUjDTQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "from nl2code_examples.django import RawDataset\n",
        "with open(dataset_path, \"rb\") as f:\n",
        "    dataset = pickle.load(f)\n",
        "dataset = RawDataset(dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrFgwHCntjkt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nl2code_examples.django import RawDataset, Entry\n",
        "train_raw_dataset = RawDataset(dataset[\"train\"])\n",
        "test_raw_dataset = RawDataset(dataset[\"test\"])\n",
        "val_raw_dataset = RawDataset(dataset[\"valid\"])\n",
        "if num_train != 0:\n",
        "    train_raw_dataset = RawDataset(list(train)[:num_train])\n",
        "    test_raw_dataset = RawDataset(list(train)[:num_train])\n",
        "    val_raw_dataset = RawDataset(list(train)[:num_train])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V0WsjTbjHOQ_",
        "colab": {}
      },
      "source": [
        "from nl2code_examples.django import DatasetEncoder\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "!mkdir -p \"$output_dir_path\"\n",
        "encoder = DatasetEncoder(train_raw_dataset.samples, word_threshold, token_threshold)\n",
        "with open(os.path.join(output_dir_path, \"encoder.pickle\"), \"wb\") as file:\n",
        "    pickle.dump(encoder, file)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11mMmXAuutb9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nl2code_examples.django import RawDataset, TrainDataset, EvalDataset\n",
        "train_dataset = TrainDataset(train_raw_dataset, encoder)\n",
        "test_dataset = EvalDataset(test_raw_dataset, encoder, max_action_length, skip_impossible_entry=False)\n",
        "valid_dataset = EvalDataset(val_raw_dataset, encoder, max_action_length, skip_impossible_entry=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcAaeUZMtqSt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nl2code_examples.django import TrainingModel\n",
        "model = TrainingModel(encoder, embedding_dim, node_type_embedding_dim,\n",
        "                      lstm_state_size, hidden_state_size,\n",
        "                      dropout)\n",
        "if device != -1:\n",
        "    model = model.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ho3IgH4e04pi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJw73TjO1CNc",
        "colab_type": "text"
      },
      "source": [
        "### Training Loop\n",
        "* Launch TensorBoard\n",
        "* Run training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPJ_QTj3Lfp2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "980d513b-e5b4-430e-fb03-cb8b7ab8c697"
      },
      "source": [
        "%load_ext tensorboard\n",
        "tensorboard_path = \"tensorboard\"\n",
        "if runtime == \"host\":\n",
        "    %tensorboard --logdir $tensorboard_path\n",
        "else:\n",
        "    !pkill tensorboard.\n",
        "    import subprocess\n",
        "    import os\n",
        "    subprocess.Popen([\"tensorboard\", \"--logdir\", tensorboard_path])\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div id=\"root\"></div>\n",
              "    <script>\n",
              "      (function() {\n",
              "        window.TENSORBOARD_ENV = window.TENSORBOARD_ENV || {};\n",
              "        window.TENSORBOARD_ENV[\"IN_COLAB\"] = true;\n",
              "        document.querySelector(\"base\").href = \"https://localhost:6006\";\n",
              "        function fixUpTensorboard(root) {\n",
              "          const tftb = root.querySelector(\"tf-tensorboard\");\n",
              "          // Disable the fragment manipulation behavior in Colab. Not\n",
              "          // only is the behavior not useful (as the iframe's location\n",
              "          // is not visible to the user), it causes TensorBoard's usage\n",
              "          // of `window.replace` to navigate away from the page and to\n",
              "          // the `localhost:<port>` URL specified by the base URI, which\n",
              "          // in turn causes the frame to (likely) crash.\n",
              "          tftb.removeAttribute(\"use-hash\");\n",
              "        }\n",
              "        function executeAllScripts(root) {\n",
              "          // When `script` elements are inserted into the DOM by\n",
              "          // assigning to an element's `innerHTML`, the scripts are not\n",
              "          // executed. Thus, we manually re-insert these scripts so that\n",
              "          // TensorBoard can initialize itself.\n",
              "          for (const script of root.querySelectorAll(\"script\")) {\n",
              "            const newScript = document.createElement(\"script\");\n",
              "            newScript.type = script.type;\n",
              "            newScript.textContent = script.textContent;\n",
              "            root.appendChild(newScript);\n",
              "            script.remove();\n",
              "          }\n",
              "        }\n",
              "        function setHeight(root, height) {\n",
              "          // We set the height dynamically after the TensorBoard UI has\n",
              "          // been initialized. This avoids an intermediate state in\n",
              "          // which the container plus the UI become taller than the\n",
              "          // final width and cause the Colab output frame to be\n",
              "          // permanently resized, eventually leading to an empty\n",
              "          // vertical gap below the TensorBoard UI. It's not clear\n",
              "          // exactly what causes this problematic intermediate state,\n",
              "          // but setting the height late seems to fix it.\n",
              "          root.style.height = `${height}px`;\n",
              "        }\n",
              "        const root = document.getElementById(\"root\");\n",
              "        fetch(\".\")\n",
              "          .then((x) => x.text())\n",
              "          .then((html) => void (root.innerHTML = html))\n",
              "          .then(() => fixUpTensorboard(root))\n",
              "          .then(() => executeAllScripts(root))\n",
              "          .then(() => setHeight(root, 800));\n",
              "      })();\n",
              "    </script>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jAPAqZYz3A2p",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm_notebook as tqdm\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.utils.rnn as rnn\n",
        "from typing import List\n",
        "from nl2code_examples.django import TrainDataset, validate\n",
        "from nl2code.nn import Loss, Accuracy\n",
        "import nl2code.nn.utils.rnn as nrnn\n",
        "from nl2code.language.python import is_subtype\n",
        "from nl2code import BeamSearchSynthesizer\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "def query_embedding(query: List[str]):\n",
        "    x = encoder.annotation_encoder.batch_encode(query)\n",
        "    if device != -1:\n",
        "        x = x.cuda()\n",
        "    embedding =  model.encoder(nrnn.pad_sequence([x]))\n",
        "    embedding = embedding.data\n",
        "    return embedding.view(len(query), -1)\n",
        "\n",
        "synthesizer = BeamSearchSynthesizer(beam_size, model.predictor,\n",
        "                                    encoder.action_sequence_encoder, is_subtype,\n",
        "                                    max_steps=max_action_length)\n",
        "writer = SummaryWriter(tensorboard_path)\n",
        "\n",
        "loss_function = Loss()\n",
        "acc_function = Accuracy()\n",
        "best_score = -1\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "    loader = DataLoader(train_dataset, batch_size=batch_size,\n",
        "                        shuffle=True,\n",
        "                        num_workers=4,\n",
        "                        collate_fn=TrainDataset.collate)\n",
        "    avg_loss = 0.0\n",
        "    model.train()\n",
        "    for i, (query, action, prev_action) in enumerate(loader):\n",
        "        query = rnn.pack_sequence(query, enforce_sorted=False)\n",
        "        action = rnn.pack_sequence(action, enforce_sorted=False)\n",
        "        prev_action_train = [x[:-1] for x in prev_action]\n",
        "        action_ground_truth = [x[1:] for x in prev_action]\n",
        "        prev_action_train = rnn.pack_sequence(prev_action_train, enforce_sorted=False)\n",
        "        action_ground_truth = rnn.pack_sequence(action_ground_truth, enforce_sorted=False)\n",
        "        if device != -1:\n",
        "            query = query.cuda()\n",
        "            action = action.cuda()\n",
        "            prev_action_train = prev_action_train.cuda()\n",
        "            action_ground_truth = action_ground_truth.cuda()\n",
        "        query = nrnn.pad_packed_sequence(query, padding_value=-1)\n",
        "        action = nrnn.pad_packed_sequence(action, padding_value=-1)\n",
        "        prev_action_train = nrnn.pad_packed_sequence(prev_action_train, padding_value=-1)\n",
        "        action_ground_truth = nrnn.pad_packed_sequence(action_ground_truth, padding_value=-1)\n",
        "\n",
        "        rule_prob, token_prob, copy_prob, _, _ = model(query, action, prev_action_train)\n",
        "        loss = loss_function(rule_prob, token_prob, copy_prob, action_ground_truth)\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        step = epoch * len(train_dataset) + i * batch_size\n",
        "        l = loss.cpu().detach().numpy()\n",
        "        avg_loss += l / len(loader)\n",
        "        writer.add_scalars('training', { \"loss\": l }, step)\n",
        "    print(epoch, avg_loss)\n",
        "\n",
        "    # Evaluate test dataset\n",
        "    if (epoch + 1) % evaluation_interval == 0:\n",
        "        model.eval()\n",
        "        accuracy = 0\n",
        "        bleu4 = 0\n",
        "        for query, query_with_placeholder, ground_truth in tqdm(test_dataset):\n",
        "            result = validate(query, query_with_placeholder, ground_truth, query_embedding, synthesizer)\n",
        "            accuracy += 1 if result.is_match else 0\n",
        "            bleu4 += result.bleu4\n",
        "        accuracy /= len(test_dataset)\n",
        "        bleu4 /= len(test_dataset)\n",
        "        writer.add_scalars('test', { \"accuracy\": accuracy, \"bleu4\": bleu4 }, epoch)\n",
        "        print(epoch, bleu4, accuracy)\n",
        "        score = bleu4\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            torch.save(model.state_dict(), os.path.join(output_dir_path, \"best_model.pickle\"))\n",
        "\n",
        "if best_score < 0:\n",
        "    torch.save(model.state_dict(), os.path.join(output_dir_path, \"best_model.pickle\"))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toeP4RGEeK1b",
        "colab_type": "text"
      },
      "source": [
        "### Run Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAjEaEWYeKGF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm_notebook as tqdm\n",
        "import os\n",
        "import pickle\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.utils.rnn as rnn\n",
        "from typing import List\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from nl2code.nn import Loss\n",
        "import nl2code.nn.utils.rnn as nrnn\n",
        "from nl2code.language.python import is_subtype\n",
        "from nl2code import BeamSearchSynthesizer\n",
        "from nl2code_examples.django import validate, unparse\n",
        "\n",
        "def query_embedding(query: List[str]):\n",
        "    x = encoder.annotation_encoder.batch_encode(query)\n",
        "    if device != -1:\n",
        "        x = x.cuda()\n",
        "    embedding =  model.encoder(nrnn.pad_sequence([x]))\n",
        "    embedding = embedding.data\n",
        "    return embedding.view(len(query), -1)\n",
        "\n",
        "synthesizer = BeamSearchSynthesizer(beam_size, model.predictor,\n",
        "                                    encoder.action_sequence_encoder, is_subtype,\n",
        "                                    max_steps=max_action_length)\n",
        "\n",
        "\n",
        "# Validate the model\n",
        "model.load_state_dict(torch.load(os.path.join(output_dir_path, \"best_model.pickle\")))\n",
        "accuracy = 0\n",
        "bleu4 = 0\n",
        "model.eval()\n",
        "results = []\n",
        "for query, query_with_placeholder, ground_truth in tqdm(valid_dataset):\n",
        "    result = validate(query, query_with_placeholder, ground_truth, query_embedding, synthesizer)\n",
        "    accuracy += 1 if result.is_match else 0\n",
        "    bleu4 += result.bleu4\n",
        "    results.append(result)\n",
        "accuracy /= len(valid_dataset)\n",
        "bleu4 /= len(valid_dataset)\n",
        "with open(os.path.join(output_dir_path, \"validation_results.pickle\"), \"wb\") as file:\n",
        "    pickle.dump(results, file)\n",
        "print(accuracy, bleu4)\n",
        "writer.add_scalars('validation', { \"accuracy\": accuracy, \"bleu4\": bleu4 })"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYIEAmUEq1PI",
        "colab_type": "text"
      },
      "source": [
        "### Post-Process\n",
        "\n",
        "* Save tensorboard output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iB3slMVq0eK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip -r \"$output_dir_path/tensorboard.zip\" $tensorboard_path"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}